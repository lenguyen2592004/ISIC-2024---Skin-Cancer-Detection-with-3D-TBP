{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4059f350",
   "metadata": {
    "papermill": {
     "duration": 0.010355,
     "end_time": "2024-10-12T07:33:21.826697",
     "exception": false,
     "start_time": "2024-10-12T07:33:21.816342",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">LIBRARIES</h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34ceabf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-12T07:33:21.847102Z",
     "iopub.status.busy": "2024-10-12T07:33:21.846450Z",
     "iopub.status.idle": "2024-10-12T07:33:27.908655Z",
     "shell.execute_reply": "2024-10-12T07:33:27.907641Z"
    },
    "papermill": {
     "duration": 6.074968,
     "end_time": "2024-10-12T07:33:27.911060",
     "exception": false,
     "start_time": "2024-10-12T07:33:21.836092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.under_sampling import NearMiss, TomekLinks\n",
    "from sklearn.impute import SimpleImputer\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import time\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif, VarianceThreshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8b45078",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-12T07:33:27.932426Z",
     "iopub.status.busy": "2024-10-12T07:33:27.931831Z",
     "iopub.status.idle": "2024-10-12T07:33:27.936937Z",
     "shell.execute_reply": "2024-10-12T07:33:27.936092Z"
    },
    "papermill": {
     "duration": 0.018201,
     "end_time": "2024-10-12T07:33:27.938827",
     "exception": false,
     "start_time": "2024-10-12T07:33:27.920626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CFG_GLOBAL:\n",
    "    num_folds = 5\n",
    "    train_folds = [0, 1, 2, 3, 4]\n",
    "\n",
    "cfg_global = CFG_GLOBAL()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638daa5b",
   "metadata": {
    "papermill": {
     "duration": 0.008853,
     "end_time": "2024-10-12T07:33:27.956618",
     "exception": false,
     "start_time": "2024-10-12T07:33:27.947765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">IMAGE MODEL 1</h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5366aa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-12T07:33:27.976414Z",
     "iopub.status.busy": "2024-10-12T07:33:27.976065Z",
     "iopub.status.idle": "2024-10-12T07:34:05.792603Z",
     "shell.execute_reply": "2024-10-12T07:34:05.791431Z"
    },
    "papermill": {
     "duration": 37.829166,
     "end_time": "2024-10-12T07:34:05.794781",
     "exception": false,
     "start_time": "2024-10-12T07:33:27.965615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/check_version.py:49: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "  data = fetch_version_info()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "This is convnextv2 family\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/2623943922.py:194: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_w_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is convnextv2 family\n",
      "This is convnextv2 family\n",
      "This is convnextv2 family\n",
      "This is convnextv2 family\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isic_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ISIC_0015657</th>\n",
       "      <td>-0.501967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0015729</th>\n",
       "      <td>-4.002757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0015740</th>\n",
       "      <td>-3.307847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                target\n",
       "isic_id               \n",
       "ISIC_0015657 -0.501967\n",
       "ISIC_0015729 -4.002757\n",
       "ISIC_0015740 -3.307847"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CFG:\n",
    "    model_name = \"convnextv2_nano.fcmae_ft_in22k_in1k\"\n",
    "    model_path = Path(\"/kaggle/input/image-features/image_1\")\n",
    "    img_size = 224 #384 or 224\n",
    "    folds = [0,1,2,3,4]\n",
    "\n",
    "    oof_path = model_path / \"oof_predictions.csv\"\n",
    "\n",
    "cfg = CFG()\n",
    "\n",
    "test_path = Path('/kaggle/input/isic-2024-challenge/test-metadata.csv')\n",
    "subm_path  = Path('/kaggle/input/isic-2024-challenge/sample_submission.csv')\n",
    "\n",
    "id_col = 'isic_id'\n",
    "\n",
    "def read_data(path, cfg):\n",
    "    return (\n",
    "        pl.read_csv(path)\n",
    "        .to_pandas()\n",
    "        .set_index(id_col)\n",
    "    )\n",
    "\n",
    "df_test = read_data(test_path, cfg)\n",
    "df_subm = pd.read_csv(subm_path, index_col=id_col)\n",
    "\n",
    "# === ImageNet inference code\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import timm\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import io\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, hdf5_file, isic_ids, targets=None, transform=None):\n",
    "        self.hdf5_file = h5py.File(hdf5_file, 'r')  # Keep file open\n",
    "        self.isic_ids = isic_ids\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.isic_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_bytes = self.hdf5_file[self.isic_ids[idx]][()]\n",
    "        img = Image.open(io.BytesIO(img_bytes))\n",
    "        img = np.array(img)\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=img)\n",
    "            img = transformed['image']\n",
    "\n",
    "        target = self.targets[idx] if self.targets is not None else torch.tensor(-1)\n",
    "        return img, target\n",
    "\n",
    "    def __del__(self):\n",
    "        self.hdf5_file.close()\n",
    "base_transform = A.Compose([\n",
    "    A.Resize(cfg.img_size, cfg.img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "\n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1.0 / p)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            self.__class__.__name__\n",
    "            + \"(\"\n",
    "            + \"p=\"\n",
    "            + \"{:.4f}\".format(self.p.data.tolist()[0])\n",
    "            + \", \"\n",
    "            + \"eps=\"\n",
    "            + str(self.eps)\n",
    "            + \")\"\n",
    "        )\n",
    "\n",
    "class ISICModel(nn.Module):\n",
    "    def __init__(self, model_name, num_classes=1, pretrained=False, checkpoint_path=None):\n",
    "        super(ISICModel, self).__init__()\n",
    "        self.model_name = model_name\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, checkpoint_path=checkpoint_path)\n",
    "        self.model_org = timm.create_model(model_name, pretrained=pretrained, checkpoint_path=checkpoint_path)\n",
    "        self.model_org.classifier = nn.Identity()\n",
    "        self.pooling = GeM()\n",
    "\n",
    "        if \"eva02\" in self.model_name:\n",
    "            in_features = self.model.head.in_features\n",
    "            self.model.head = nn.Identity()\n",
    "        elif \"efficientnetv2\" in self.model_name:\n",
    "            in_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Identity()\n",
    "            if self.pooling:  # My custom pooling\n",
    "                self.model.global_pool = nn.Identity()\n",
    "        elif \"convnextv2\" in self.model_name:\n",
    "            print(\"This is convnextv2 family\")\n",
    "            in_features = self.model.head.fc.in_features\n",
    "            self.model.head = nn.Identity()\n",
    "            self.head = nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(640, 256),\n",
    "                nn.ReLU(), \n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(256, num_classes),\n",
    "            )\n",
    "        self.linear = nn.Linear(in_features, num_classes)\n",
    "        self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])\n",
    "\n",
    "    def forward(self, images):\n",
    "        features = self.model(images)\n",
    "\n",
    "        if \"efficientnetv2\" in self.model_name:\n",
    "            if self.pooling:\n",
    "                features = self.pooling(features).flatten(1)\n",
    "\n",
    "        if \"convnextv2\" in self.model_name:\n",
    "            output = self.head(features)\n",
    "        else:\n",
    "            for i, dropout in enumerate(self.dropouts):\n",
    "                if i == 0:\n",
    "                    output = self.linear(dropout(features))\n",
    "                else:\n",
    "                    output += self.linear(dropout(features))\n",
    "            output /= len(self.dropouts)\n",
    "\n",
    "        return output.squeeze()\n",
    "\n",
    "\n",
    "\n",
    "def get_latest_epoch_file(folder_path, target_fold):\n",
    "    pattern = re.compile(r\"fold_(\\d+)_epoch_(\\d+)_score_(\\d+\\.\\d+)\\.pth\")\n",
    "\n",
    "    max_epoch = -1\n",
    "    latest_file = None\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            fold, epoch, score = match.groups() \n",
    "            fold = int(fold)\n",
    "            epoch = int(epoch)\n",
    "\n",
    "            if fold == target_fold and epoch > max_epoch:\n",
    "                max_epoch = epoch\n",
    "                latest_file = filename\n",
    "\n",
    "    if latest_file:\n",
    "        return os.path.join(folder_path, latest_file)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def load_models(folds, device):\n",
    "    models = []\n",
    "    for fold in folds:\n",
    "        model = ISICModel(cfg.model_name)\n",
    "        model.to(device)\n",
    "        model_w_path = get_latest_epoch_file(cfg.model_path, fold)\n",
    "        model.load_state_dict(torch.load(model_w_path, map_location=device))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "\n",
    "@torch.no_grad()  \n",
    "def ensemble_predict(models, test_loader, device):\n",
    "    all_predictions = []\n",
    "    for inputs, _ in tqdm(test_loader, desc=\"Predicting\"):\n",
    "        inputs = inputs.to(device)\n",
    "        fold_predictions = torch.stack([model(inputs) for model in models])\n",
    "        avg_predictions = fold_predictions.mean(dim=0)\n",
    "        all_predictions.extend(avg_predictions.cpu().numpy())\n",
    "    return all_predictions\n",
    "\n",
    "\n",
    "TEST_HDF5_FILE_PATH = '/kaggle/input/isic-2024-challenge/test-image.hdf5'\n",
    "\n",
    "# Set up CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# folds to use for pred\n",
    "folds = cfg.folds\n",
    "\n",
    "models = load_models(folds, device)\n",
    "\n",
    "# Prepare your test dataset\n",
    "test_dataset = ISICDataset(\n",
    "    hdf5_file=TEST_HDF5_FILE_PATH,\n",
    "    isic_ids=df_test.index.values,  #minor change here from\n",
    "    transform=base_transform,\n",
    ")\n",
    "\n",
    "# Create test data loader\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Run predictions\n",
    "predictions = ensemble_predict(models, test_loader, device)\n",
    "\n",
    "# Create a new DataFrame with predictions\n",
    "temp_df = pd.DataFrame({\"image_predict\": predictions}, index=df_test.index)\n",
    "\n",
    "# Join the predictions to df_test\n",
    "df_test = df_test.join(temp_df)\n",
    "\n",
    "df_subm[\"target\"] = df_test[\"image_predict\"]\n",
    "\n",
    "df_subm.to_csv(f'submission_1.csv')\n",
    "df_subm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab877f8",
   "metadata": {
    "papermill": {
     "duration": 0.009998,
     "end_time": "2024-10-12T07:34:05.815349",
     "exception": false,
     "start_time": "2024-10-12T07:34:05.805351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">IMAGE MODEL 2</h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1111024",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-12T07:34:05.837664Z",
     "iopub.status.busy": "2024-10-12T07:34:05.837318Z",
     "iopub.status.idle": "2024-10-12T07:34:08.107838Z",
     "shell.execute_reply": "2024-10-12T07:34:08.106711Z"
    },
    "papermill": {
     "duration": 2.284637,
     "end_time": "2024-10-12T07:34:08.110256",
     "exception": false,
     "start_time": "2024-10-12T07:34:05.825619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/4077759250.py:240: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_w_path, map_location=device))\n",
      "Predicting: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isic_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ISIC_0015657</th>\n",
       "      <td>-2.714859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0015729</th>\n",
       "      <td>-5.223221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0015740</th>\n",
       "      <td>-4.123434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                target\n",
       "isic_id               \n",
       "ISIC_0015657 -2.714859\n",
       "ISIC_0015729 -5.223221\n",
       "ISIC_0015740 -4.123434"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CFG:\n",
    "    model_name = \"vit_tiny_patch16_224.augreg_in21k_ft_in1k\"\n",
    "    model_path = Path(f\"/kaggle/input/image-features/image_2\")\n",
    "    img_size = 224 #384 or 224\n",
    "    folds = [0,1,2,3,4]\n",
    "\n",
    "    # auto\n",
    "    oof_path = model_path / \"oof_predictions.csv\"\n",
    "\n",
    "cfg = CFG()\n",
    "\n",
    "test_path = Path('/kaggle/input/isic-2024-challenge/test-metadata.csv')\n",
    "subm_path  = Path('/kaggle/input/isic-2024-challenge/sample_submission.csv')\n",
    "\n",
    "id_col = 'isic_id'\n",
    "\n",
    "def read_data(path, cfg):\n",
    "    return (\n",
    "        pl.read_csv(path)\n",
    "        .to_pandas()\n",
    "        .set_index(id_col)\n",
    "    )\n",
    "\n",
    "df_test = read_data(test_path, cfg)\n",
    "df_subm = pd.read_csv(subm_path, index_col=id_col)\n",
    "\n",
    "# === ImageNet inference code\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import timm\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import io\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, hdf5_file, isic_ids, targets=None, transform=None):\n",
    "        self.hdf5_file = h5py.File(hdf5_file, 'r')  # Keep file open\n",
    "        self.isic_ids = isic_ids\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.isic_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_bytes = self.hdf5_file[self.isic_ids[idx]][()]\n",
    "        img = Image.open(io.BytesIO(img_bytes))\n",
    "        img = np.array(img)\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=img)\n",
    "            img = transformed['image']\n",
    "\n",
    "        target = self.targets[idx] if self.targets is not None else torch.tensor(-1)\n",
    "        return img, target\n",
    "\n",
    "    def __del__(self):\n",
    "        self.hdf5_file.close()  # Ensure file is closed when object is destroyed\n",
    "\n",
    "# Define the albumentations transformation\n",
    "base_transform = A.Compose([\n",
    "    A.Resize(cfg.img_size, cfg.img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "\n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1.0 / p)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            self.__class__.__name__\n",
    "            + \"(\"\n",
    "            + \"p=\"\n",
    "            + \"{:.4f}\".format(self.p.data.tolist()[0])\n",
    "            + \", \"\n",
    "            + \"eps=\"\n",
    "            + str(self.eps)\n",
    "            + \")\"\n",
    "        )\n",
    "\n",
    "class ISICModel(nn.Module):\n",
    "    def __init__(self, model_name, num_classes=1, pretrained=False, checkpoint_path=None):\n",
    "        super(ISICModel, self).__init__()\n",
    "        self.model_name = model_name\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, checkpoint_path=checkpoint_path)\n",
    "\n",
    "        if \"eva02\" in self.model_name:\n",
    "            in_features = self.model.head.in_features\n",
    "            self.model.head = nn.Identity()\n",
    "            self.linear = nn.Linear(in_features, num_classes)\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])\n",
    "        elif \"efficientnetv2\" in self.model_name:\n",
    "            in_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Identity()\n",
    "            self.pooling = GeM()\n",
    "            if self.pooling:  # My custom pooling\n",
    "                self.model.global_pool = nn.Identity()\n",
    "            self.linear = nn.Linear(in_features, num_classes)\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])\n",
    "        elif \"convnextv2\" in self.model_name:\n",
    "            in_features = self.model.head.fc.in_features\n",
    "            self.model.head = nn.Identity()\n",
    "            self.head = nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d((1, 1)),  # Global Average Pooling\n",
    "                nn.Flatten(),  # フラット化\n",
    "                nn.Linear(in_features, 256),  # 新しい全結合層1\n",
    "                nn.ReLU(),  # 活性化関数\n",
    "                nn.Dropout(0.5),  # ドロップアウト\n",
    "                nn.Linear(256, num_classes),  # 出力層（2クラス分類）\n",
    "            )\n",
    "        elif \"swinv2\" in self.model_name:\n",
    "            in_features = self.model.head.fc.in_features\n",
    "            self.model.head = nn.Identity()\n",
    "            self.feature_extractor = nn.Sequential(\n",
    "                # nn.AdaptiveAvgPool2d((1, 1)),  # Global Average Pooling\n",
    "                GeM(),\n",
    "                nn.Flatten(),  # フラット化\n",
    "                nn.Linear(in_features, 256),  # 新しい全結合層1\n",
    "                nn.ReLU(),  # 活性化関数\n",
    "            )\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])  # 5つのDropout\n",
    "            self.classifier = nn.Linear(256, num_classes)  # 出力層（2クラス分類）\n",
    "        elif \"vit_tiny\" in self.model_name:\n",
    "            in_features = self.model.head.in_features\n",
    "            self.model.norm = nn.Identity()\n",
    "            self.model.fc_norm = nn.Identity()\n",
    "            self.model.head_drop = nn.Identity()\n",
    "            self.model.head = nn.Identity()\n",
    "            self.feature_extractor = nn.Sequential(\n",
    "                nn.Flatten(),  # フラット化\n",
    "                nn.Linear(in_features, 64),  # 新しい全結合層1\n",
    "                nn.ReLU(),  # 活性化関数\n",
    "            )\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(1)])  # 5つのDropout\n",
    "            self.classifier = nn.Linear(64, num_classes)  # 出力層（2クラス分類）\n",
    "\n",
    "    def forward(self, images):\n",
    "        features = self.model(images)\n",
    "\n",
    "        if any(\n",
    "            [\n",
    "                \"efficientnetv2\" in self.model_name,\n",
    "                \"eva02\" in self.model_name,\n",
    "            ]\n",
    "        ):\n",
    "            # Custom poolingがある場合\n",
    "            if self.pooling:\n",
    "                features = self.pooling(features).flatten(1)\n",
    "            for i, dropout in enumerate(self.dropouts):\n",
    "                if i == 0:\n",
    "                    output = self.linear(dropout(features))\n",
    "                else:\n",
    "                    output += self.linear(dropout(features))\n",
    "            output /= len(self.dropouts)\n",
    "\n",
    "        if \"convnextv2\" in self.model_name:\n",
    "            output = self.head(features)\n",
    "\n",
    "        if \"swinv2\" in self.model_name:\n",
    "            features = self.feature_extractor(features)\n",
    "            output = torch.mean(torch.stack([dropout(features) for dropout in self.dropouts]), dim=0)\n",
    "            output = self.classifier(output)\n",
    "\n",
    "        if \"vit_tiny\" in self.model_name:\n",
    "            features = self.feature_extractor(features)\n",
    "            output = torch.mean(torch.stack([dropout(features) for dropout in self.dropouts]), dim=0)\n",
    "            output = self.classifier(output)\n",
    "\n",
    "        return output.squeeze()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_latest_epoch_file(folder_path, target_fold):\n",
    "    # 正規表現パターン：fold_X_epoch_Y_score_Z.pth の形式に一致\n",
    "    pattern = re.compile(r\"fold_(\\d+)_epoch_(\\d+)_score_(\\d+\\.\\d+)\\.pth\") # 新パターン\n",
    "#     pattern = re.compile(r\"model_fold_(\\d+)_epoch_(\\d+)\\.pth\") # 旧パターン\n",
    "\n",
    "    max_epoch = -1\n",
    "    latest_file = None\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            fold, epoch, score = match.groups() # 新パターン\n",
    "#             fold, epoch = match.groups() # 旧パターン\n",
    "            fold = int(fold)\n",
    "            epoch = int(epoch)\n",
    "\n",
    "            if fold == target_fold and epoch > max_epoch:\n",
    "                max_epoch = epoch\n",
    "                latest_file = filename\n",
    "\n",
    "    if latest_file:\n",
    "        return os.path.join(folder_path, latest_file)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def load_models(folds, device):\n",
    "    models = []\n",
    "    for fold in folds:\n",
    "        model = ISICModel(cfg.model_name)\n",
    "        model.to(device)\n",
    "        model_w_path = get_latest_epoch_file(cfg.model_path, fold)\n",
    "        model.load_state_dict(torch.load(model_w_path, map_location=device))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "\n",
    "@torch.no_grad()  # Apply no_grad to the entire function\n",
    "def ensemble_predict(models, test_loader, device):\n",
    "    all_predictions = []\n",
    "    for inputs, _ in tqdm(test_loader, desc=\"Predicting\"):\n",
    "        inputs = inputs.to(device)\n",
    "#         fold_predictions = torch.stack([model(inputs).softmax(dim=1)[:, 1] for model in models])\n",
    "        fold_predictions = torch.stack([model(inputs) for model in models])\n",
    "        avg_predictions = fold_predictions.mean(dim=0)\n",
    "        all_predictions.extend(avg_predictions.cpu().numpy())\n",
    "    return all_predictions\n",
    "\n",
    "\n",
    "# === Do ImageNet inference on test data / merge df_test\n",
    "TEST_HDF5_FILE_PATH = '/kaggle/input/isic-2024-challenge/test-image.hdf5'\n",
    "\n",
    "# Set up CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# folds to use for pred\n",
    "folds = cfg.folds\n",
    "\n",
    "models = load_models(folds, device)\n",
    "\n",
    "# Prepare your test dataset\n",
    "test_dataset = ISICDataset(\n",
    "    hdf5_file=TEST_HDF5_FILE_PATH,\n",
    "    isic_ids=df_test.index.values,  #minor change here from\n",
    "    transform=base_transform,\n",
    ")\n",
    "\n",
    "# Create test data loader\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Run predictions\n",
    "predictions = ensemble_predict(models, test_loader, device)\n",
    "\n",
    "# Create a new DataFrame with predictions\n",
    "temp_df = pd.DataFrame({\"image_predict\": predictions}, index=df_test.index)\n",
    "\n",
    "# Join the predictions to df_test\n",
    "df_test = df_test.join(temp_df)\n",
    "\n",
    "df_subm[\"target\"] = df_test[\"image_predict\"]\n",
    "\n",
    "df_subm.to_csv(f'submission_2.csv')\n",
    "df_subm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa34f816",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T19:10:19.724754Z",
     "iopub.status.busy": "2024-08-30T19:10:19.724439Z",
     "iopub.status.idle": "2024-08-30T19:10:19.729474Z",
     "shell.execute_reply": "2024-08-30T19:10:19.728591Z",
     "shell.execute_reply.started": "2024-08-30T19:10:19.724728Z"
    },
    "papermill": {
     "duration": 0.0106,
     "end_time": "2024-10-12T07:34:08.131975",
     "exception": false,
     "start_time": "2024-10-12T07:34:08.121375",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">IMAGE MODEL 3</h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0911a88d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-12T07:34:08.155566Z",
     "iopub.status.busy": "2024-10-12T07:34:08.155188Z",
     "iopub.status.idle": "2024-10-12T07:34:10.298101Z",
     "shell.execute_reply": "2024-10-12T07:34:10.297039Z"
    },
    "papermill": {
     "duration": 2.157507,
     "end_time": "2024-10-12T07:34:10.300126",
     "exception": false,
     "start_time": "2024-10-12T07:34:08.142619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/2516198820.py:250: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_w_path, map_location=device))\n",
      "Predicting: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isic_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ISIC_0015657</th>\n",
       "      <td>-1.637331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0015729</th>\n",
       "      <td>-3.406027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0015740</th>\n",
       "      <td>-4.912541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                target\n",
       "isic_id               \n",
       "ISIC_0015657 -1.637331\n",
       "ISIC_0015729 -3.406027\n",
       "ISIC_0015740 -4.912541"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CFG:\n",
    "    model_name = \"vit_tiny_patch16_224.augreg_in21k_ft_in1k\"\n",
    "    model_path = Path(f\"/kaggle/input/image-features/image_3\")\n",
    "    img_size = 224 #384 or 224\n",
    "    folds = [0,1,2,3,4]\n",
    "\n",
    "    # auto\n",
    "    oof_path = model_path / \"oof_predictions.csv\"\n",
    "\n",
    "    # --- desctiption\n",
    "        # \"cv\":  0.147796,\n",
    "        # \"lb\": ,\n",
    "        # \"version\": \"\",\n",
    "        # \"config\": \"vit_tiny_patch16_224.augreg_in21k_ft_in1k\",\n",
    "        # \"date\": 20240830233240,\n",
    "        # \"desc\": \"lr1e-4 + warmup + train1:1-val1:10 + upsample-2 + AugumentMore + Dropoutx1 + CustomHead + weight_decay1e-3\",\n",
    "        # \"desc\": \"remap case1\",\n",
    "    # ---------------\n",
    "\n",
    "cfg = CFG()\n",
    "\n",
    "test_path = Path('/kaggle/input/isic-2024-challenge/test-metadata.csv')\n",
    "subm_path  = Path('/kaggle/input/isic-2024-challenge/sample_submission.csv')\n",
    "\n",
    "id_col = 'isic_id'\n",
    "\n",
    "def read_data(path, cfg):\n",
    "    return (\n",
    "        pl.read_csv(path)\n",
    "        .to_pandas()\n",
    "        .set_index(id_col)\n",
    "    )\n",
    "\n",
    "df_test = read_data(test_path, cfg)\n",
    "df_subm = pd.read_csv(subm_path, index_col=id_col)\n",
    "\n",
    "# === ImageNet inference code\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import timm\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import io\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, hdf5_file, isic_ids, targets=None, transform=None):\n",
    "        self.hdf5_file = h5py.File(hdf5_file, 'r')  # Keep file open\n",
    "        self.isic_ids = isic_ids\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.isic_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_bytes = self.hdf5_file[self.isic_ids[idx]][()]\n",
    "        img = Image.open(io.BytesIO(img_bytes))\n",
    "        img = np.array(img)\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=img)\n",
    "            img = transformed['image']\n",
    "\n",
    "        target = self.targets[idx] if self.targets is not None else torch.tensor(-1)\n",
    "        return img, target\n",
    "\n",
    "    def __del__(self):\n",
    "        self.hdf5_file.close()  # Ensure file is closed when object is destroyed\n",
    "\n",
    "# Define the albumentations transformation\n",
    "base_transform = A.Compose([\n",
    "    A.Resize(cfg.img_size, cfg.img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "\n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1.0 / p)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            self.__class__.__name__\n",
    "            + \"(\"\n",
    "            + \"p=\"\n",
    "            + \"{:.4f}\".format(self.p.data.tolist()[0])\n",
    "            + \", \"\n",
    "            + \"eps=\"\n",
    "            + str(self.eps)\n",
    "            + \")\"\n",
    "        )\n",
    "\n",
    "class ISICModel(nn.Module):\n",
    "    def __init__(self, model_name, num_classes=1, pretrained=False, checkpoint_path=None):\n",
    "        super(ISICModel, self).__init__()\n",
    "        self.model_name = model_name\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, checkpoint_path=checkpoint_path)\n",
    "\n",
    "        if \"eva02\" in self.model_name:\n",
    "            in_features = self.model.head.in_features\n",
    "            self.model.head = nn.Identity()\n",
    "            self.linear = nn.Linear(in_features, num_classes)\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])\n",
    "        elif \"efficientnetv2\" in self.model_name:\n",
    "            in_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Identity()\n",
    "            self.pooling = GeM()\n",
    "            if self.pooling:  # My custom pooling\n",
    "                self.model.global_pool = nn.Identity()\n",
    "            self.linear = nn.Linear(in_features, num_classes)\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])\n",
    "        elif \"convnextv2\" in self.model_name:\n",
    "            in_features = self.model.head.fc.in_features\n",
    "            self.model.head = nn.Identity()\n",
    "            self.head = nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d((1, 1)),  # Global Average Pooling\n",
    "                nn.Flatten(),  # フラット化\n",
    "                nn.Linear(in_features, 256),  # 新しい全結合層1\n",
    "                nn.ReLU(),  # 活性化関数\n",
    "                nn.Dropout(0.5),  # ドロップアウト\n",
    "                nn.Linear(256, num_classes),  # 出力層（2クラス分類）\n",
    "            )\n",
    "        elif \"swinv2\" in self.model_name:\n",
    "            in_features = self.model.head.fc.in_features\n",
    "            self.model.head = nn.Identity()\n",
    "            self.feature_extractor = nn.Sequential(\n",
    "                # nn.AdaptiveAvgPool2d((1, 1)),  # Global Average Pooling\n",
    "                GeM(),\n",
    "                nn.Flatten(),  # フラット化\n",
    "                nn.Linear(in_features, 256),  # 新しい全結合層1\n",
    "                nn.ReLU(),  # 活性化関数\n",
    "            )\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])  # 5つのDropout\n",
    "            self.classifier = nn.Linear(256, num_classes)  # 出力層（2クラス分類）\n",
    "        elif \"vit_tiny\" in self.model_name:\n",
    "            in_features = self.model.head.in_features\n",
    "            self.model.norm = nn.Identity()\n",
    "            self.model.fc_norm = nn.Identity()\n",
    "            self.model.head_drop = nn.Identity()\n",
    "            self.model.head = nn.Identity()\n",
    "            self.feature_extractor = nn.Sequential(\n",
    "                nn.Flatten(),  # フラット化\n",
    "                nn.Linear(in_features, 64),  # 新しい全結合層1\n",
    "                nn.ReLU(),  # 活性化関数\n",
    "            )\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(1)])  # 5つのDropout\n",
    "            self.classifier = nn.Linear(64, num_classes)  # 出力層（2クラス分類）\n",
    "\n",
    "    def forward(self, images):\n",
    "        features = self.model(images)\n",
    "\n",
    "        if any(\n",
    "            [\n",
    "                \"efficientnetv2\" in self.model_name,\n",
    "                \"eva02\" in self.model_name,\n",
    "            ]\n",
    "        ):\n",
    "            # Custom poolingがある場合\n",
    "            if self.pooling:\n",
    "                features = self.pooling(features).flatten(1)\n",
    "            for i, dropout in enumerate(self.dropouts):\n",
    "                if i == 0:\n",
    "                    output = self.linear(dropout(features))\n",
    "                else:\n",
    "                    output += self.linear(dropout(features))\n",
    "            output /= len(self.dropouts)\n",
    "\n",
    "        if \"convnextv2\" in self.model_name:\n",
    "            output = self.head(features)\n",
    "\n",
    "        if \"swinv2\" in self.model_name:\n",
    "            features = self.feature_extractor(features)\n",
    "            output = torch.mean(torch.stack([dropout(features) for dropout in self.dropouts]), dim=0)\n",
    "            output = self.classifier(output)\n",
    "\n",
    "        if \"vit_tiny\" in self.model_name:\n",
    "            features = self.feature_extractor(features)\n",
    "            output = torch.mean(torch.stack([dropout(features) for dropout in self.dropouts]), dim=0)\n",
    "            output = self.classifier(output)\n",
    "\n",
    "        return output.squeeze()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_latest_epoch_file(folder_path, target_fold):\n",
    "    # 正規表現パターン：fold_X_epoch_Y_score_Z.pth の形式に一致\n",
    "    pattern = re.compile(r\"fold_(\\d+)_epoch_(\\d+)_score_(\\d+\\.\\d+)\\.pth\") # 新パターン\n",
    "#     pattern = re.compile(r\"model_fold_(\\d+)_epoch_(\\d+)\\.pth\") # 旧パターン\n",
    "\n",
    "    max_epoch = -1\n",
    "    latest_file = None\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            fold, epoch, score = match.groups() # 新パターン\n",
    "#             fold, epoch = match.groups() # 旧パターン\n",
    "            fold = int(fold)\n",
    "            epoch = int(epoch)\n",
    "\n",
    "            if fold == target_fold and epoch > max_epoch:\n",
    "                max_epoch = epoch\n",
    "                latest_file = filename\n",
    "\n",
    "    if latest_file:\n",
    "        return os.path.join(folder_path, latest_file)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def load_models(folds, device):\n",
    "    models = []\n",
    "    for fold in folds:\n",
    "        model = ISICModel(cfg.model_name)\n",
    "        model.to(device)\n",
    "        model_w_path = get_latest_epoch_file(cfg.model_path, fold)\n",
    "        model.load_state_dict(torch.load(model_w_path, map_location=device))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "\n",
    "@torch.no_grad()  # Apply no_grad to the entire function\n",
    "def ensemble_predict(models, test_loader, device):\n",
    "    all_predictions = []\n",
    "    for inputs, _ in tqdm(test_loader, desc=\"Predicting\"):\n",
    "        inputs = inputs.to(device)\n",
    "#         fold_predictions = torch.stack([model(inputs).softmax(dim=1)[:, 1] for model in models])\n",
    "        fold_predictions = torch.stack([model(inputs) for model in models])\n",
    "        avg_predictions = fold_predictions.mean(dim=0)\n",
    "        all_predictions.extend(avg_predictions.cpu().numpy())\n",
    "    return all_predictions\n",
    "\n",
    "\n",
    "# === Do ImageNet inference on test data / merge df_test\n",
    "TEST_HDF5_FILE_PATH = '/kaggle/input/isic-2024-challenge/test-image.hdf5'\n",
    "\n",
    "# Set up CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# folds to use for pred\n",
    "folds = cfg.folds\n",
    "\n",
    "models = load_models(folds, device)\n",
    "\n",
    "# Prepare your test dataset\n",
    "test_dataset = ISICDataset(\n",
    "    hdf5_file=TEST_HDF5_FILE_PATH,\n",
    "    isic_ids=df_test.index.values,  #minor change here from\n",
    "    transform=base_transform,\n",
    ")\n",
    "\n",
    "# Create test data loader\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Run predictions\n",
    "predictions = ensemble_predict(models, test_loader, device)\n",
    "\n",
    "# Create a new DataFrame with predictions\n",
    "temp_df = pd.DataFrame({\"image_predict\": predictions}, index=df_test.index)\n",
    "\n",
    "# Join the predictions to df_test\n",
    "df_test = df_test.join(temp_df)\n",
    "\n",
    "df_subm[\"target\"] = df_test[\"image_predict\"]\n",
    "\n",
    "df_subm.to_csv(f'submission_3.csv')\n",
    "df_subm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11971b72",
   "metadata": {
    "papermill": {
     "duration": 0.01123,
     "end_time": "2024-10-12T07:34:10.323125",
     "exception": false,
     "start_time": "2024-10-12T07:34:10.311895",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">IMAGE MODEL 4</h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "433706a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-12T07:34:10.349547Z",
     "iopub.status.busy": "2024-10-12T07:34:10.349161Z",
     "iopub.status.idle": "2024-10-12T07:34:16.982703Z",
     "shell.execute_reply": "2024-10-12T07:34:16.981684Z"
    },
    "papermill": {
     "duration": 6.650003,
     "end_time": "2024-10-12T07:34:16.984689",
     "exception": false,
     "start_time": "2024-10-12T07:34:10.334686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/4191355621.py:308: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_w_path, map_location=device))\n",
      "Predicting: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isic_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ISIC_0015657</th>\n",
       "      <td>-2.898454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0015729</th>\n",
       "      <td>-4.748341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0015740</th>\n",
       "      <td>-6.205088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                target\n",
       "isic_id               \n",
       "ISIC_0015657 -2.898454\n",
       "ISIC_0015729 -4.748341\n",
       "ISIC_0015740 -6.205088"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CFG:\n",
    "    model_name = \"vit_small_patch16_224.augreg_in21k_ft_in1k\"\n",
    "    model_path = Path(f\"/kaggle/input/image-features/image_4\")\n",
    "    img_size = 224 #384 or 224\n",
    "    folds = [0,1,2,3,4]\n",
    "\n",
    "    # auto\n",
    "    oof_path = model_path / \"oof_predictions.csv\"\n",
    "\n",
    "    # --- desctiption\n",
    "        # \"cv\":  0.1486832,\n",
    "        # \"lb\": ,\n",
    "        # \"version\": \"\",\n",
    "        # \"config\": \"vit_small_patch16_224.augreg_in21k_ft_in1k\",\n",
    "        # \"date\": 20240902001446,\n",
    "        # \"desc\": \"lr1e-4 + warmup + train1:1-val1:10 + upsample-2 + AugumentMore + Dropoutx1 + CustomHead-64 + weight_decay1e-3\",\n",
    "        # \"desc\": \"remap case1\",\n",
    "    # ---------------\n",
    "\n",
    "cfg = CFG()\n",
    "\n",
    "test_path = Path('/kaggle/input/isic-2024-challenge/test-metadata.csv')\n",
    "subm_path  = Path('/kaggle/input/isic-2024-challenge/sample_submission.csv')\n",
    "\n",
    "id_col = 'isic_id'\n",
    "\n",
    "def read_data(path, cfg):\n",
    "    return (\n",
    "        pl.read_csv(path)\n",
    "        .to_pandas()\n",
    "        .set_index(id_col)\n",
    "    )\n",
    "\n",
    "df_test = read_data(test_path, cfg)\n",
    "df_subm = pd.read_csv(subm_path, index_col=id_col)\n",
    "\n",
    "# === ImageNet inference code\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import timm\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import io\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, hdf5_file, isic_ids, targets=None, transform=None):\n",
    "        self.hdf5_file = h5py.File(hdf5_file, 'r')  # Keep file open\n",
    "        self.isic_ids = isic_ids\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.isic_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_bytes = self.hdf5_file[self.isic_ids[idx]][()]\n",
    "        img = Image.open(io.BytesIO(img_bytes))\n",
    "        img = np.array(img)\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=img)\n",
    "            img = transformed['image']\n",
    "\n",
    "        target = self.targets[idx] if self.targets is not None else torch.tensor(-1)\n",
    "        return img, target\n",
    "\n",
    "    def __del__(self):\n",
    "        self.hdf5_file.close()  # Ensure file is closed when object is destroyed\n",
    "\n",
    "# Define the albumentations transformation\n",
    "base_transform = A.Compose([\n",
    "    A.Resize(cfg.img_size, cfg.img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "\n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1.0 / p)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            self.__class__.__name__\n",
    "            + \"(\"\n",
    "            + \"p=\"\n",
    "            + \"{:.4f}\".format(self.p.data.tolist()[0])\n",
    "            + \", \"\n",
    "            + \"eps=\"\n",
    "            + str(self.eps)\n",
    "            + \")\"\n",
    "        )\n",
    "\n",
    "class ISICModel(nn.Module):\n",
    "    def __init__(self, model_name, num_classes=1, pretrained=False, checkpoint_path=None):\n",
    "        super(ISICModel, self).__init__()\n",
    "        self.model_name = model_name\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, checkpoint_path=checkpoint_path)\n",
    "\n",
    "        if \"eva02_small_patch14_336\" in self.model_name:\n",
    "            in_features = self.model.head.in_features\n",
    "            self.model.head = nn.Identity()\n",
    "            self.linear = nn.Linear(in_features, num_classes)\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])\n",
    "        elif \"eva02_small_patch14_224\" in self.model_name:\n",
    "            self.feature_extractor = nn.Sequential(\n",
    "                nn.Flatten(),  # フラット化\n",
    "                nn.Linear(192, 32),  # 新しい全結合層1\n",
    "                nn.ReLU(),  # 活性化関数\n",
    "            )\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])  # 5つのDropout\n",
    "            self.classifier = nn.Linear(32, num_classes)  # 出力層（2クラス分類）\n",
    "        elif \"eva02_tiny_patch14_224\" in self.model_name:\n",
    "            self.feature_extractor = nn.Sequential(\n",
    "                nn.Flatten(),  # フラット化\n",
    "                nn.Linear(192, 32),  # 新しい全結合層1\n",
    "                nn.ReLU(),  # 活性化関数\n",
    "            )\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])  # 5つのDropout\n",
    "            self.classifier = nn.Linear(32, num_classes)  # 出力層（2クラス分類）\n",
    "        elif \"efficientnetv2\" in self.model_name:\n",
    "            in_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Identity()\n",
    "            self.pooling = GeM()\n",
    "            if self.pooling:  # My custom pooling\n",
    "                self.model.global_pool = nn.Identity()\n",
    "            self.linear = nn.Linear(in_features, num_classes)\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])\n",
    "        elif \"convnextv2_atto\" in self.model_name:\n",
    "            in_features = self.model.head.fc.in_features\n",
    "            self.model.head = nn.Identity()\n",
    "            self.feature_extractor = nn.Sequential(\n",
    "                # nn.AdaptiveAvgPool2d((1, 1)),  # Global Average Pooling\n",
    "                GeM(),\n",
    "                nn.Flatten(),  # フラット化\n",
    "                nn.Linear(in_features, 32),  # 新しい全結合層1\n",
    "                nn.ReLU(),  # 活性化関数\n",
    "            )\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])  # 5つのDropout\n",
    "            self.classifier = nn.Linear(32, num_classes)  # 出力層（2クラス分類）\n",
    "        elif \"convnextv2_nano\" in self.model_name:\n",
    "            in_features = self.model.head.fc.in_features\n",
    "            self.model.head = nn.Identity()\n",
    "            self.feature_extractor = nn.Sequential(\n",
    "                # nn.AdaptiveAvgPool2d((1, 1)),  # Global Average Pooling\n",
    "                GeM(),\n",
    "                nn.Flatten(),  # フラット化\n",
    "                nn.Linear(in_features, 256),  # 新しい全結合層1\n",
    "                nn.ReLU(),  # 活性化関数\n",
    "            )\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])  # 5つのDropout\n",
    "            self.classifier = nn.Linear(256, num_classes)  # 出力層（2クラス分類）\n",
    "        elif \"swinv2\" in self.model_name:\n",
    "            in_features = self.model.head.fc.in_features\n",
    "            self.model.head = nn.Identity()\n",
    "            self.feature_extractor = nn.Sequential(\n",
    "                # nn.AdaptiveAvgPool2d((1, 1)),  # Global Average Pooling\n",
    "                GeM(),\n",
    "                nn.Flatten(),  # フラット化\n",
    "                nn.Linear(in_features, 256),  # 新しい全結合層1\n",
    "                nn.ReLU(),  # 活性化関数\n",
    "            )\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])  # 5つのDropout\n",
    "            self.classifier = nn.Linear(256, num_classes)  # 出力層（2クラス分類）\n",
    "        elif \"vit_tiny\" in self.model_name:\n",
    "            in_features = self.model.head.in_features\n",
    "            self.model.norm = nn.Identity()\n",
    "            self.model.fc_norm = nn.Identity()\n",
    "            self.model.head_drop = nn.Identity()\n",
    "            self.model.head = nn.Identity()\n",
    "            self.feature_extractor = nn.Sequential(\n",
    "                nn.Flatten(),  # フラット化\n",
    "                nn.Linear(in_features, 64),  # 新しい全結合層1\n",
    "                nn.ReLU(),  # 活性化関数\n",
    "            )\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(1)])  # 5つのDropout\n",
    "            self.classifier = nn.Linear(64, num_classes)  # 出力層（2クラス分類）\n",
    "        elif \"vit_small\" in self.model_name:\n",
    "            in_features = self.model.head.in_features\n",
    "            self.model.norm = nn.Identity()\n",
    "            self.model.fc_norm = nn.Identity()\n",
    "            self.model.head_drop = nn.Identity()\n",
    "            self.model.head = nn.Identity()\n",
    "            self.feature_extractor = nn.Sequential(\n",
    "                nn.Flatten(),  # フラット化\n",
    "                nn.Linear(in_features, 64),  # 新しい全結合層1\n",
    "                nn.ReLU(),  # 活性化関数\n",
    "            )\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(1)])  # 5つのDropout\n",
    "            self.classifier = nn.Linear(64, num_classes)  # 出力層（2クラス分類）\n",
    "\n",
    "    def forward(self, images):\n",
    "        features = self.model(images)\n",
    "\n",
    "        if any(\n",
    "            [\n",
    "                \"efficientnetv2\" in self.model_name,\n",
    "                \"eva02_small_patch14_336\" in self.model_name,\n",
    "            ]\n",
    "        ):\n",
    "            # Custom poolingがある場合\n",
    "            if self.pooling:\n",
    "                features = self.pooling(features).flatten(1)\n",
    "            for i, dropout in enumerate(self.dropouts):\n",
    "                if i == 0:\n",
    "                    output = self.linear(dropout(features))\n",
    "                else:\n",
    "                    output += self.linear(dropout(features))\n",
    "            output /= len(self.dropouts)\n",
    "\n",
    "            features = self.feature_extractor(features)\n",
    "            output = torch.mean(torch.stack([dropout(features) for dropout in self.dropouts]), dim=0)\n",
    "            output = self.classifier(output)\n",
    "\n",
    "        if \"eva02_small_patch14_224\" in self.model_name:\n",
    "            features = self.feature_extractor(features)\n",
    "            output = torch.mean(torch.stack([dropout(features) for dropout in self.dropouts]), dim=0)\n",
    "            output = self.classifier(output)\n",
    "\n",
    "        if \"eva02_tiny_patch14_224\" in self.model_name:\n",
    "            features = self.feature_extractor(features)\n",
    "            output = torch.mean(torch.stack([dropout(features) for dropout in self.dropouts]), dim=0)\n",
    "            output = self.classifier(output)\n",
    "\n",
    "        if \"convnextv2\" in self.model_name:\n",
    "            features = self.feature_extractor(features)\n",
    "            output = torch.mean(torch.stack([dropout(features) for dropout in self.dropouts]), dim=0)\n",
    "            output = self.classifier(output)\n",
    "\n",
    "        if \"swinv2\" in self.model_name:\n",
    "            features = self.feature_extractor(features)\n",
    "            output = torch.mean(torch.stack([dropout(features) for dropout in self.dropouts]), dim=0)\n",
    "            output = self.classifier(output)\n",
    "\n",
    "        if \"vit_tiny\" in self.model_name:\n",
    "            features = self.feature_extractor(features)\n",
    "            output = torch.mean(torch.stack([dropout(features) for dropout in self.dropouts]), dim=0)\n",
    "            output = self.classifier(output)\n",
    "        if \"vit_small\" in self.model_name:\n",
    "            features = self.feature_extractor(features)\n",
    "            output = torch.mean(torch.stack([dropout(features) for dropout in self.dropouts]), dim=0)\n",
    "            output = self.classifier(output)\n",
    "\n",
    "        return output.squeeze()\n",
    "\n",
    "\n",
    "def get_latest_epoch_file(folder_path, target_fold):\n",
    "    pattern = re.compile(r\"fold_(\\d+)_epoch_(\\d+)_score_(\\d+\\.\\d+)\\.pth\") \n",
    "\n",
    "    max_epoch = -1\n",
    "    latest_file = None\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            fold, epoch, score = match.groups() # 新パターン\n",
    "#             fold, epoch = match.groups() # 旧パターン\n",
    "            fold = int(fold)\n",
    "            epoch = int(epoch)\n",
    "\n",
    "            if fold == target_fold and epoch > max_epoch:\n",
    "                max_epoch = epoch\n",
    "                latest_file = filename\n",
    "\n",
    "    if latest_file:\n",
    "        return os.path.join(folder_path, latest_file)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def load_models(folds, device):\n",
    "    models = []\n",
    "    for fold in folds:\n",
    "        model = ISICModel(cfg.model_name)\n",
    "        model.to(device)\n",
    "        model_w_path = get_latest_epoch_file(cfg.model_path, fold)\n",
    "        model.load_state_dict(torch.load(model_w_path, map_location=device))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "\n",
    "@torch.no_grad()  # Apply no_grad to the entire function\n",
    "def ensemble_predict(models, test_loader, device):\n",
    "    all_predictions = []\n",
    "    for inputs, _ in tqdm(test_loader, desc=\"Predicting\"):\n",
    "        inputs = inputs.to(device)\n",
    "        fold_predictions = torch.stack([model(inputs) for model in models])\n",
    "        avg_predictions = fold_predictions.mean(dim=0)\n",
    "        all_predictions.extend(avg_predictions.cpu().numpy())\n",
    "    return all_predictions\n",
    "\n",
    "\n",
    "# === Do ImageNet inference on test data / merge df_test\n",
    "TEST_HDF5_FILE_PATH = '/kaggle/input/isic-2024-challenge/test-image.hdf5'\n",
    "\n",
    "# Set up CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# folds to use for pred\n",
    "folds = cfg.folds\n",
    "\n",
    "models = load_models(folds, device)\n",
    "\n",
    "# Prepare your test dataset\n",
    "test_dataset = ISICDataset(\n",
    "    hdf5_file=TEST_HDF5_FILE_PATH,\n",
    "    isic_ids=df_test.index.values,  #minor change here from\n",
    "    transform=base_transform,\n",
    ")\n",
    "\n",
    "# Create test data loader\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Run predictions\n",
    "predictions = ensemble_predict(models, test_loader, device)\n",
    "\n",
    "# Create a new DataFrame with predictions\n",
    "temp_df = pd.DataFrame({\"image_predict\": predictions}, index=df_test.index)\n",
    "\n",
    "# Join the predictions to df_test\n",
    "df_test = df_test.join(temp_df)\n",
    "\n",
    "df_subm[\"target\"] = df_test[\"image_predict\"]\n",
    "\n",
    "df_subm.to_csv(f'submission_4.csv')\n",
    "df_subm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517cf4b4",
   "metadata": {
    "papermill": {
     "duration": 0.012019,
     "end_time": "2024-10-12T07:34:17.009248",
     "exception": false,
     "start_time": "2024-10-12T07:34:16.997229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">DATA PREPROCESSING</h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39cb96a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-12T07:34:17.035206Z",
     "iopub.status.busy": "2024-10-12T07:34:17.034826Z",
     "iopub.status.idle": "2024-10-12T07:34:17.050632Z",
     "shell.execute_reply": "2024-10-12T07:34:17.049816Z"
    },
    "papermill": {
     "duration": 0.031284,
     "end_time": "2024-10-12T07:34:17.052494",
     "exception": false,
     "start_time": "2024-10-12T07:34:17.021210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = Path('/kaggle/input/isic-2024-challenge')\n",
    "\n",
    "train_path = root / 'train-metadata.csv'\n",
    "test_path = root / 'test-metadata.csv'\n",
    "subm_path = root / 'sample_submission.csv'\n",
    "\n",
    "id_col = 'isic_id'\n",
    "target_col = 'target'\n",
    "group_col = 'patient_id'\n",
    "\n",
    "err = 1e-5\n",
    "sampling_ratio = 0.01\n",
    "seed = 42\n",
    "\n",
    "num_cols = [\n",
    "    'age_approx',                        # Approximate age of patient at time of imaging.\n",
    "    'clin_size_long_diam_mm',            # Maximum diameter of the lesion (mm).+\n",
    "    'tbp_lv_A',                          # A inside  lesion.+\n",
    "    'tbp_lv_Aext',                       # A outside lesion.+\n",
    "    'tbp_lv_B',                          # B inside  lesion.+\n",
    "    'tbp_lv_Bext',                       # B outside lesion.+\n",
    "    'tbp_lv_C',                          # Chroma inside  lesion.+\n",
    "    'tbp_lv_Cext',                       # Chroma outside lesion.+\n",
    "    'tbp_lv_H',                          # Hue inside the lesion; calculated as the angle of A* and B* in LAB* color space. Typical values range from 25 (red) to 75 (brown).+\n",
    "    'tbp_lv_Hext',                       # Hue outside lesion.+\n",
    "    'tbp_lv_L',                          # L inside lesion.+\n",
    "    'tbp_lv_Lext',                       # L outside lesion.+\n",
    "    'tbp_lv_areaMM2',                    # Area of lesion (mm^2).+\n",
    "    'tbp_lv_area_perim_ratio',           # Border jaggedness, the ratio between lesions perimeter and area. Circular lesions will have low values; irregular shaped lesions will have higher values. Values range 0-10.+\n",
    "    'tbp_lv_color_std_mean',             # Color irregularity, calculated as the variance of colors within the lesion's boundary.\n",
    "    'tbp_lv_deltaA',                     # Average A contrast (inside vs. outside lesion).+\n",
    "    'tbp_lv_deltaB',                     # Average B contrast (inside vs. outside lesion).+\n",
    "    'tbp_lv_deltaL',                     # Average L contrast (inside vs. outside lesion).+\n",
    "    'tbp_lv_deltaLB',                    #\n",
    "    'tbp_lv_deltaLBnorm',                # Contrast between the lesion and its immediate surrounding skin. Low contrast lesions tend to be faintly visible such as freckles; high contrast lesions tend to be those with darker pigment. Calculated as the average delta LB of the lesion relative to its immediate background in LAB* color space. Typical values range from 5.5 to 25.+\n",
    "    'tbp_lv_eccentricity',               # Eccentricity.+\n",
    "    'tbp_lv_minorAxisMM',                # Smallest lesion diameter (mm).+\n",
    "    'tbp_lv_nevi_confidence',            # Nevus confidence score (0-100 scale) is a convolutional neural network classifier estimated probability that the lesion is a nevus. The neural network was trained on approximately 57,000 lesions that were classified and labeled by a dermatologist.+,++\n",
    "    'tbp_lv_norm_border',                # Border irregularity (0-10 scale); the normalized average of border jaggedness and asymmetry.+\n",
    "    'tbp_lv_norm_color',                 # Color variation (0-10 scale); the normalized average of color asymmetry and color irregularity.+\n",
    "    'tbp_lv_perimeterMM',                # Perimeter of lesion (mm).+\n",
    "    'tbp_lv_radial_color_std_max',       # Color asymmetry, a measure of asymmetry of the spatial distribution of color within the lesion. This score is calculated by looking at the average standard deviation in LAB* color space within concentric rings originating from the lesion center. Values range 0-10.+\n",
    "    'tbp_lv_stdL',                       # Standard deviation of L inside  lesion.+\n",
    "    'tbp_lv_stdLExt',                    # Standard deviation of L outside lesion.+\n",
    "    'tbp_lv_symm_2axis',                 # Border asymmetry; a measure of asymmetry of the lesion's contour about an axis perpendicular to the lesion's most symmetric axis. Lesions with two axes of symmetry will therefore have low scores (more symmetric), while lesions with only one or zero axes of symmetry will have higher scores (less symmetric). This score is calculated by comparing opposite halves of the lesion contour over many degrees of rotation. The angle where the halves are most similar identifies the principal axis of symmetry, while the second axis of symmetry is perpendicular to the principal axis. Border asymmetry is reported as the asymmetry value about this second axis. Values range 0-10.+\n",
    "    'tbp_lv_symm_2axis_angle',           # Lesion border asymmetry angle.+\n",
    "    'tbp_lv_x',                          # X-coordinate of the lesion on 3D TBP.+\n",
    "    'tbp_lv_y',                          # Y-coordinate of the lesion on 3D TBP.+\n",
    "    'tbp_lv_z',                          # Z-coordinate of the lesion on 3D TBP.+\n",
    "]\n",
    "\n",
    "new_num_cols = [\n",
    "    'lesion_size_ratio',             # tbp_lv_minorAxisMM      / clin_size_long_diam_mm\n",
    "    'lesion_shape_index',            # tbp_lv_areaMM2          / tbp_lv_perimeterMM **2\n",
    "    'hue_contrast',                  # tbp_lv_H                - tbp_lv_Hext              abs\n",
    "    'luminance_contrast',            # tbp_lv_L                - tbp_lv_Lext              abs\n",
    "    'lesion_color_difference',       # tbp_lv_deltaA **2       + tbp_lv_deltaB **2 + tbp_lv_deltaL **2  sqrt\n",
    "    'border_complexity',             # tbp_lv_norm_border      + tbp_lv_symm_2axis\n",
    "    'color_uniformity',              # tbp_lv_color_std_mean   / tbp_lv_radial_color_std_max\n",
    "\n",
    "    'position_distance_3d',          # tbp_lv_x **2 + tbp_lv_y **2 + tbp_lv_z **2  sqrt\n",
    "    'perimeter_to_area_ratio',       # tbp_lv_perimeterMM      / tbp_lv_areaMM2\n",
    "    'area_to_perimeter_ratio',       # tbp_lv_areaMM2          / tbp_lv_perimeterMM\n",
    "    'lesion_visibility_score',       # tbp_lv_deltaLBnorm      + tbp_lv_norm_color\n",
    "    'symmetry_border_consistency',   # tbp_lv_symm_2axis       * tbp_lv_norm_border\n",
    "    'consistency_symmetry_border',   # tbp_lv_symm_2axis       * tbp_lv_norm_border / (tbp_lv_symm_2axis + tbp_lv_norm_border)\n",
    "\n",
    "    'color_consistency',             # tbp_lv_stdL             / tbp_lv_Lext\n",
    "    'consistency_color',             # tbp_lv_stdL*tbp_lv_Lext / tbp_lv_stdL + tbp_lv_Lext\n",
    "    'size_age_interaction',          # clin_size_long_diam_mm  * age_approx\n",
    "    'hue_color_std_interaction',     # tbp_lv_H                * tbp_lv_color_std_mean\n",
    "    'lesion_severity_index',         # tbp_lv_norm_border      + tbp_lv_norm_color + tbp_lv_eccentricity / 3\n",
    "    'shape_complexity_index',        # border_complexity       + lesion_shape_index\n",
    "    'color_contrast_index',          # tbp_lv_deltaA + tbp_lv_deltaB + tbp_lv_deltaL + tbp_lv_deltaLBnorm\n",
    "\n",
    "    'log_lesion_area',               # tbp_lv_areaMM2          + 1  np.log\n",
    "    'normalized_lesion_size',        # clin_size_long_diam_mm  / age_approx\n",
    "    'mean_hue_difference',           # tbp_lv_H                + tbp_lv_Hext    / 2\n",
    "    'std_dev_contrast',              # tbp_lv_deltaA **2 + tbp_lv_deltaB **2 + tbp_lv_deltaL **2   / 3  np.sqrt\n",
    "    'color_shape_composite_index',   # tbp_lv_color_std_mean   + bp_lv_area_perim_ratio + tbp_lv_symm_2axis   / 3\n",
    "    'lesion_orientation_3d',         # tbp_lv_y                , tbp_lv_x  np.arctan2\n",
    "    'overall_color_difference',      # tbp_lv_deltaA           + tbp_lv_deltaB + tbp_lv_deltaL   / 3\n",
    "\n",
    "    'symmetry_perimeter_interaction',# tbp_lv_symm_2axis       * tbp_lv_perimeterMM\n",
    "    'comprehensive_lesion_index',    # tbp_lv_area_perim_ratio + tbp_lv_eccentricity + bp_lv_norm_color + tbp_lv_symm_2axis   / 4\n",
    "    'color_variance_ratio',          # tbp_lv_color_std_mean   / tbp_lv_stdLExt\n",
    "    'border_color_interaction',      # tbp_lv_norm_border      * tbp_lv_norm_color\n",
    "    'border_color_interaction_2',\n",
    "    'size_color_contrast_ratio',     # clin_size_long_diam_mm  / tbp_lv_deltaLBnorm\n",
    "    'age_normalized_nevi_confidence',# tbp_lv_nevi_confidence  / age_approx\n",
    "    'age_normalized_nevi_confidence_2',\n",
    "    'color_asymmetry_index',         # tbp_lv_symm_2axis       * tbp_lv_radial_color_std_max\n",
    "\n",
    "    'volume_approximation_3d',       # tbp_lv_areaMM2          * sqrt(tbp_lv_x**2 + tbp_lv_y**2 + tbp_lv_z**2)\n",
    "    'color_range',                   # abs(tbp_lv_L - tbp_lv_Lext) + abs(tbp_lv_A - tbp_lv_Aext) + abs(tbp_lv_B - tbp_lv_Bext)\n",
    "    'shape_color_consistency',       # tbp_lv_eccentricity     * tbp_lv_color_std_mean\n",
    "    'border_length_ratio',           # tbp_lv_perimeterMM      / pi * sqrt(tbp_lv_areaMM2 / pi)\n",
    "    'age_size_symmetry_index',       # age_approx              * clin_size_long_diam_mm * tbp_lv_symm_2axis\n",
    "    'index_age_size_symmetry',       # age_approx              * tbp_lv_areaMM2 * tbp_lv_symm_2axis\n",
    "]\n",
    "\n",
    "cat_cols = ['sex', 'anatom_site_general', 'tbp_tile_type', 'tbp_lv_location', 'tbp_lv_location_simple', 'attribution']\n",
    "norm_cols = [f'{col}_patient_norm' for col in num_cols + new_num_cols]\n",
    "special_cols = ['count_per_patient']\n",
    "image_cols = [\n",
    "    \"image_1\",\n",
    "    \"image_2\",\n",
    "    \"image_3\",\n",
    "    \"image_4\",\n",
    "]\n",
    "\n",
    "feature_cols = num_cols + new_num_cols + cat_cols + norm_cols + special_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a74fc0e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-12T07:34:17.078423Z",
     "iopub.status.busy": "2024-10-12T07:34:17.077911Z",
     "iopub.status.idle": "2024-10-12T07:34:17.104579Z",
     "shell.execute_reply": "2024-10-12T07:34:17.103682Z"
    },
    "papermill": {
     "duration": 0.041833,
     "end_time": "2024-10-12T07:34:17.106499",
     "exception": false,
     "start_time": "2024-10-12T07:34:17.064666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    return (\n",
    "        pl.read_csv(path)\n",
    "        .with_columns(\n",
    "            pl.col('age_approx').cast(pl.String).replace('NA', np.nan).cast(pl.Float64),\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col(pl.Float64).fill_nan(pl.col(pl.Float64).median()), # You may want to impute test data with train\n",
    "        )\n",
    "        .with_columns(\n",
    "            lesion_size_ratio              = pl.col('tbp_lv_minorAxisMM') / pl.col('clin_size_long_diam_mm'),\n",
    "            lesion_shape_index             = pl.col('tbp_lv_areaMM2') / (pl.col('tbp_lv_perimeterMM') ** 2),\n",
    "            hue_contrast                   = (pl.col('tbp_lv_H') - pl.col('tbp_lv_Hext')).abs(),\n",
    "            luminance_contrast             = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs(),\n",
    "            lesion_color_difference        = (pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2).sqrt(),\n",
    "            border_complexity              = pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_symm_2axis'),\n",
    "            color_uniformity               = pl.col('tbp_lv_color_std_mean') / (pl.col('tbp_lv_radial_color_std_max') + err),\n",
    "        )\n",
    "        .with_columns(\n",
    "            position_distance_3d           = (pl.col('tbp_lv_x') ** 2 + pl.col('tbp_lv_y') ** 2 + pl.col('tbp_lv_z') ** 2).sqrt(),\n",
    "            perimeter_to_area_ratio        = pl.col('tbp_lv_perimeterMM') / pl.col('tbp_lv_areaMM2'),\n",
    "            area_to_perimeter_ratio        = pl.col('tbp_lv_areaMM2') / pl.col('tbp_lv_perimeterMM'),\n",
    "            lesion_visibility_score        = pl.col('tbp_lv_deltaLBnorm') + pl.col('tbp_lv_norm_color'),\n",
    "            combined_anatomical_site       = pl.col('anatom_site_general') + '_' + pl.col('tbp_lv_location'),\n",
    "            symmetry_border_consistency    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border'),\n",
    "            consistency_symmetry_border    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border') / (pl.col('tbp_lv_symm_2axis') + pl.col('tbp_lv_norm_border')),\n",
    "        )\n",
    "        .with_columns(\n",
    "            color_consistency              = pl.col('tbp_lv_stdL') / pl.col('tbp_lv_Lext'),\n",
    "            consistency_color              = pl.col('tbp_lv_stdL') * pl.col('tbp_lv_Lext') / (pl.col('tbp_lv_stdL') + pl.col('tbp_lv_Lext')),\n",
    "            size_age_interaction           = pl.col('clin_size_long_diam_mm') * pl.col('age_approx'),\n",
    "            hue_color_std_interaction      = pl.col('tbp_lv_H') * pl.col('tbp_lv_color_std_mean'),\n",
    "            lesion_severity_index          = (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_eccentricity')) / 3,\n",
    "            shape_complexity_index         = pl.col('border_complexity') + pl.col('lesion_shape_index'),\n",
    "            color_contrast_index           = pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL') + pl.col('tbp_lv_deltaLBnorm'),\n",
    "        )\n",
    "        .with_columns(\n",
    "            log_lesion_area                = (pl.col('tbp_lv_areaMM2') + 1).log(),\n",
    "            normalized_lesion_size         = pl.col('clin_size_long_diam_mm') / pl.col('age_approx'),\n",
    "            mean_hue_difference            = (pl.col('tbp_lv_H') + pl.col('tbp_lv_Hext')) / 2,\n",
    "            std_dev_contrast               = ((pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2) / 3).sqrt(),\n",
    "            color_shape_composite_index    = (pl.col('tbp_lv_color_std_mean') + pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_symm_2axis')) / 3,\n",
    "            lesion_orientation_3d          = pl.arctan2(pl.col('tbp_lv_y'), pl.col('tbp_lv_x')),\n",
    "            overall_color_difference       = (pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL')) / 3,\n",
    "        )\n",
    "        .with_columns(\n",
    "            symmetry_perimeter_interaction = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_perimeterMM'),\n",
    "            comprehensive_lesion_index     = (pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_eccentricity') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_symm_2axis')) / 4,\n",
    "            color_variance_ratio           = pl.col('tbp_lv_color_std_mean') / pl.col('tbp_lv_stdLExt'),\n",
    "            border_color_interaction       = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color'),\n",
    "            border_color_interaction_2     = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color') / (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color')),\n",
    "            size_color_contrast_ratio      = pl.col('clin_size_long_diam_mm') / pl.col('tbp_lv_deltaLBnorm'),\n",
    "            age_normalized_nevi_confidence = pl.col('tbp_lv_nevi_confidence') / pl.col('age_approx'),\n",
    "            age_normalized_nevi_confidence_2 = (pl.col('clin_size_long_diam_mm')**2 + pl.col('age_approx')**2).sqrt(),\n",
    "            color_asymmetry_index          = pl.col('tbp_lv_radial_color_std_max') * pl.col('tbp_lv_symm_2axis'),\n",
    "        )\n",
    "        .with_columns(\n",
    "            volume_approximation_3d        = pl.col('tbp_lv_areaMM2') * (pl.col('tbp_lv_x')**2 + pl.col('tbp_lv_y')**2 + pl.col('tbp_lv_z')**2).sqrt(),\n",
    "            color_range                    = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs() + (pl.col('tbp_lv_A') - pl.col('tbp_lv_Aext')).abs() + (pl.col('tbp_lv_B') - pl.col('tbp_lv_Bext')).abs(),\n",
    "            shape_color_consistency        = pl.col('tbp_lv_eccentricity') * pl.col('tbp_lv_color_std_mean'),\n",
    "            border_length_ratio            = pl.col('tbp_lv_perimeterMM') / (2 * np.pi * (pl.col('tbp_lv_areaMM2') / np.pi).sqrt()),\n",
    "            age_size_symmetry_index        = pl.col('age_approx') * pl.col('clin_size_long_diam_mm') * pl.col('tbp_lv_symm_2axis'),\n",
    "            index_age_size_symmetry        = pl.col('age_approx') * pl.col('tbp_lv_areaMM2') * pl.col('tbp_lv_symm_2axis'),\n",
    "        )\n",
    "        .with_columns(\n",
    "            ((pl.col(col) - pl.col(col).mean().over('patient_id')) / (pl.col(col).std().over('patient_id') + err)).alias(f'{col}_patient_norm') for col in (num_cols + new_num_cols)\n",
    "        )\n",
    "        .with_columns(\n",
    "            count_per_patient = pl.col('isic_id').count().over('patient_id'),\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col(cat_cols).cast(pl.Categorical),\n",
    "        )\n",
    "        .to_pandas()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceff76d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-12T07:34:17.132205Z",
     "iopub.status.busy": "2024-10-12T07:34:17.131649Z",
     "iopub.status.idle": "2024-10-12T07:34:17.144881Z",
     "shell.execute_reply": "2024-10-12T07:34:17.144162Z"
    },
    "papermill": {
     "duration": 0.028225,
     "end_time": "2024-10-12T07:34:17.146779",
     "exception": false,
     "start_time": "2024-10-12T07:34:17.118554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(df_train, df_test):\n",
    "    global cat_cols\n",
    "\n",
    "    encoder = OneHotEncoder(sparse_output=False, dtype=np.int32, handle_unknown='ignore')\n",
    "    encoder.fit(df_train[cat_cols])\n",
    "\n",
    "    new_cat_cols = [f'onehot_{i}' for i in range(len(encoder.get_feature_names_out()))]\n",
    "\n",
    "    df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n",
    "    df_train[new_cat_cols] = df_train[new_cat_cols].astype('category')\n",
    "\n",
    "    df_test[new_cat_cols] = encoder.transform(df_test[cat_cols])\n",
    "    df_test[new_cat_cols] = df_test[new_cat_cols].astype('category')\n",
    "\n",
    "    df_train_image = pd.read_csv(f\"/kaggle/input/image-features/image_1/oof_predictions.csv\")\n",
    "\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_train_image = df_train_image.reset_index(drop=True)\n",
    "    df_train[f\"image_1\"] = df_train_image[\"oof_prediction\"]\n",
    "\n",
    "    df_test_image = pd.read_csv(f\"submission_1.csv\")\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "    df_test_image = df_test_image.reset_index(drop=True)\n",
    "\n",
    "    df_test[f\"image_1\"] = df_test_image[\"target\"]\n",
    "\n",
    "    df_train_image = pd.read_csv(f\"/kaggle/input/image-features/image_2/oof_predictions.csv\")\n",
    "\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_train_image = df_train_image.reset_index(drop=True)\n",
    "    df_train[f\"image_2\"] = df_train_image[\"oof_prediction\"]\n",
    "\n",
    "    df_test_image = pd.read_csv(f\"submission_2.csv\")\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "    df_test_image = df_test_image.reset_index(drop=True)\n",
    "\n",
    "    df_test[f\"image_2\"] = df_test_image[\"target\"]\n",
    "\n",
    "\n",
    "    df_train_image = pd.read_csv(f\"/kaggle/input/image-features/image_3/oof_predictions.csv\")\n",
    "\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_train_image = df_train_image.reset_index(drop=True)\n",
    "    df_train[f\"image_3\"] = df_train_image[\"oof_prediction\"]\n",
    "\n",
    "    df_test_image = pd.read_csv(f\"submission_3.csv\")\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "    df_test_image = df_test_image.reset_index(drop=True)\n",
    "\n",
    "    df_test[f\"image_3\"] = df_test_image[\"target\"]\n",
    "\n",
    "    df_train_image = pd.read_csv(f\"/kaggle/input/image-features/image_4/oof_predictions.csv\")\n",
    "\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_train_image = df_train_image.reset_index(drop=True)\n",
    "    df_train[f\"image_4\"] = df_train_image[\"oof_prediction\"]\n",
    "\n",
    "    df_test_image = pd.read_csv(f\"submission_4.csv\")\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "    df_test_image = df_test_image.reset_index(drop=True)\n",
    "\n",
    "    df_test[f\"image_4\"] = df_test_image[\"target\"]\n",
    "\n",
    "    for col in cat_cols:\n",
    "        feature_cols.remove(col)\n",
    "\n",
    "    feature_cols.extend(new_cat_cols)\n",
    "    cat_cols = new_cat_cols\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6b034ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-12T07:34:17.172892Z",
     "iopub.status.busy": "2024-10-12T07:34:17.172187Z",
     "iopub.status.idle": "2024-10-12T07:34:17.177971Z",
     "shell.execute_reply": "2024-10-12T07:34:17.177134Z"
    },
    "papermill": {
     "duration": 0.020753,
     "end_time": "2024-10-12T07:34:17.179774",
     "exception": false,
     "start_time": "2024-10-12T07:34:17.159021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_metric(y_hat, y_true):\n",
    "    # y_hat = estimator.predict_proba(X)[:, 1]\n",
    "    min_tpr = 0.80\n",
    "    max_fpr = abs(1 - min_tpr)\n",
    "\n",
    "    v_gt = abs(y_true - 1)\n",
    "    v_pred = np.array([1.0 - x for x in y_hat])\n",
    "\n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "\n",
    "    return partial_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3495492",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-12T07:34:17.205181Z",
     "iopub.status.busy": "2024-10-12T07:34:17.204878Z",
     "iopub.status.idle": "2024-10-12T07:34:27.363708Z",
     "shell.execute_reply": "2024-10-12T07:34:27.362671Z"
    },
    "papermill": {
     "duration": 10.174179,
     "end_time": "2024-10-12T07:34:27.366088",
     "exception": false,
     "start_time": "2024-10-12T07:34:17.191909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = read_data(train_path)\n",
    "df_test = read_data(test_path)\n",
    "df_subm = pd.read_csv(subm_path, index_col=id_col)\n",
    "\n",
    "df_train, df_test = preprocess(df_train, df_test)\n",
    "\n",
    "df_train[\"iddx_2\"] = df_train[\"iddx_2\"].replace(\"\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0610fe9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-12T07:34:27.392125Z",
     "iopub.status.busy": "2024-10-12T07:34:27.391779Z",
     "iopub.status.idle": "2024-10-12T07:34:28.025526Z",
     "shell.execute_reply": "2024-10-12T07:34:28.024564Z"
    },
    "papermill": {
     "duration": 0.649311,
     "end_time": "2024-10-12T07:34:28.027897",
     "exception": false,
     "start_time": "2024-10-12T07:34:27.378586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Summary (patients per fold):\n",
      "Fold 0: 206 patients\n",
      "Fold 1: 209 patients\n",
      "Fold 2: 208 patients\n",
      "Fold 3: 209 patients\n",
      "Fold 4: 210 patients\n",
      "Total patients: 1042\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "df_train[\"fold\"] = -1\n",
    "for idx, (train_idx, val_idx) in enumerate(gkf.split(df_train, df_train[\"target\"], groups=df_train[\"patient_id\"])):\n",
    "    df_train.loc[val_idx, \"fold\"] = idx\n",
    "\n",
    "# Add summary\n",
    "fold_summary = df_train.groupby(\"fold\")[\"patient_id\"].nunique().to_dict()\n",
    "total_patients = df_train[\"patient_id\"].nunique()\n",
    "\n",
    "print(f\"Fold Summary (patients per fold):\")\n",
    "for fold, count in fold_summary.items():\n",
    "    if fold != -1:\n",
    "        print(f\"Fold {fold}: {count} patients\")\n",
    "print(f\"Total patients: {total_patients}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9df5a388",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-12T07:34:28.053590Z",
     "iopub.status.busy": "2024-10-12T07:34:28.053234Z",
     "iopub.status.idle": "2024-10-12T07:34:29.050709Z",
     "shell.execute_reply": "2024-10-12T07:34:29.049676Z"
    },
    "papermill": {
     "duration": 1.012643,
     "end_time": "2024-10-12T07:34:29.052867",
     "exception": false,
     "start_time": "2024-10-12T07:34:28.040224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Indeterminate\n",
      "fold  target\n",
      "0     0         19\n",
      "1     0         28\n",
      "2     0         19\n",
      "3     0         27\n",
      "4     0         21\n",
      "Name: count, dtype: int64\n",
      "--------------------\n",
      "iddx_2\n",
      "fold  target\n",
      "0     0         123\n",
      "      1          90\n",
      "1     0         131\n",
      "      1          88\n",
      "2     0         130\n",
      "      1          65\n",
      "3     0         160\n",
      "      1          81\n",
      "4     0         131\n",
      "      1          69\n",
      "Name: count, dtype: int64\n",
      "--------------------\n",
      "Confirm the validity of the process (confirm that Indeterminate in Target = 0 is gone)\n",
      "fold  target  iddx_1   \n",
      "0     0       Benign       80001\n",
      "      1       Malignant       90\n",
      "1     0       Benign       79993\n",
      "      1       Malignant       88\n",
      "2     0       Benign       80016\n",
      "      1       Malignant       65\n",
      "3     0       Benign       79970\n",
      "      1       Malignant       81\n",
      "4     0       Benign       80011\n",
      "      1       Malignant       69\n",
      "Name: count, dtype: int64\n",
      "--------------------\n",
      "Confirm the validity of the process (confirm that IDDX_2 in Target = 0 is gone)\n",
      "fold  target  iddx_2                                                  \n",
      "0     1       Malignant adnexal epithelial proliferations - Follicular    43\n",
      "              Malignant melanocytic proliferations (Melanoma)             29\n",
      "              Malignant epidermal proliferations                          18\n",
      "1     1       Malignant melanocytic proliferations (Melanoma)             36\n",
      "              Malignant adnexal epithelial proliferations - Follicular    34\n",
      "              Malignant epidermal proliferations                          18\n",
      "2     1       Malignant melanocytic proliferations (Melanoma)             32\n",
      "              Malignant adnexal epithelial proliferations - Follicular    26\n",
      "              Malignant epidermal proliferations                           7\n",
      "3     1       Malignant melanocytic proliferations (Melanoma)             31\n",
      "              Malignant adnexal epithelial proliferations - Follicular    30\n",
      "              Malignant epidermal proliferations                          20\n",
      "4     1       Malignant adnexal epithelial proliferations - Follicular    30\n",
      "              Malignant melanocytic proliferations (Melanoma)             29\n",
      "              Malignant epidermal proliferations                          10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Additional Filter\n",
    "print(\"-\"*20)\n",
    "print(\"Indeterminate\")\n",
    "print(df_train[df_train[\"iddx_1\"]==\"Indeterminate\"].groupby(\"fold\")[\"target\"].value_counts())\n",
    "\n",
    "print(\"-\"*20)\n",
    "print(\"iddx_2\")\n",
    "print(df_train[df_train[\"iddx_2\"].notna()].groupby(\"fold\")[\"target\"].value_counts())\n",
    "\n",
    "exclude_isic_ids = []\n",
    "filter = (df_train[\"target\"] == 0) & (df_train[\"iddx_1\"] == \"Indeterminate\")\n",
    "exclude_isic_ids.extend(df_train[filter][\"isic_id\"].values.tolist())\n",
    "filter = (df_train[\"target\"] == 0) & (df_train[\"iddx_2\"].notna())\n",
    "exclude_isic_ids.extend(df_train[filter][\"isic_id\"].values.tolist())\n",
    "\n",
    "exclude_isic_ids = list(set(exclude_isic_ids))\n",
    "\n",
    "print(\"-\"*20)\n",
    "print(\"Confirm the validity of the process (confirm that Indeterminate in Target = 0 is gone)\")\n",
    "print(df_train[~df_train[\"isic_id\"].isin(exclude_isic_ids)].groupby([\"fold\", \"target\"])[\"iddx_1\"].value_counts())\n",
    "\n",
    "print(\"-\"*20)\n",
    "print(\"Confirm the validity of the process (confirm that IDDX_2 in Target = 0 is gone)\")\n",
    "print(df_train[~df_train[\"isic_id\"].isin(exclude_isic_ids)].groupby([\"fold\", \"target\"])[\"iddx_2\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99fd84b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-12T07:34:29.080522Z",
     "iopub.status.busy": "2024-10-12T07:34:29.080156Z",
     "iopub.status.idle": "2024-10-12T07:34:29.320675Z",
     "shell.execute_reply": "2024-10-12T07:34:29.319486Z"
    },
    "papermill": {
     "duration": 0.257217,
     "end_time": "2024-10-12T07:34:29.323364",
     "exception": false,
     "start_time": "2024-10-12T07:34:29.066147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#they are detected at the first run\n",
    "least_important_features = ['onehot_32', 'onehot_6', 'onehot_33', 'onehot_30', 'onehot_26', 'onehot_22', 'onehot_36', 'onehot_4']\n",
    "df_train.drop(columns =least_important_features,inplace = True)\n",
    "for feature in least_important_features:\n",
    "    cat_cols.remove(feature)\n",
    "    feature_cols.remove(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113f3b35",
   "metadata": {
    "papermill": {
     "duration": 0.014816,
     "end_time": "2024-10-12T07:34:29.352450",
     "exception": false,
     "start_time": "2024-10-12T07:34:29.337634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">MODEL INITIALIZATION</h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92660687",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-12T07:34:29.383767Z",
     "iopub.status.busy": "2024-10-12T07:34:29.383354Z",
     "iopub.status.idle": "2024-10-12T07:34:29.390151Z",
     "shell.execute_reply": "2024-10-12T07:34:29.389198Z"
    },
    "papermill": {
     "duration": 0.024834,
     "end_time": "2024-10-12T07:34:29.392317",
     "exception": false,
     "start_time": "2024-10-12T07:34:29.367483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import copy\n",
    "\n",
    "feature_cols_without_image_cols = copy.copy(feature_cols)\n",
    "feature_cols += image_cols\n",
    "\n",
    "class SelectColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "021a89ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-12T07:34:29.424232Z",
     "iopub.status.busy": "2024-10-12T07:34:29.423886Z",
     "iopub.status.idle": "2024-10-12T07:34:29.429989Z",
     "shell.execute_reply": "2024-10-12T07:34:29.429013Z"
    },
    "papermill": {
     "duration": 0.024092,
     "end_time": "2024-10-12T07:34:29.432166",
     "exception": false,
     "start_time": "2024-10-12T07:34:29.408074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'objective':        'binary',\n",
    "    'verbosity':        -1,\n",
    "    'n_iter':           200,\n",
    "    'boosting_type':    'gbdt',\n",
    "    'lambda_l1':        0.08758718919397321,\n",
    "    'lambda_l2':        0.0039689175176025465,\n",
    "    'learning_rate':    0.03231007103195577,\n",
    "    'max_depth':        4,\n",
    "    'num_leaves':       103,\n",
    "    'colsample_bytree': 0.8329551585827726,\n",
    "    'colsample_bynode': 0.4025961355653304,\n",
    "    'bagging_fraction': 0.7738954452473223,\n",
    "    'bagging_freq':     4,\n",
    "    'min_data_in_leaf': 85,\n",
    "    'scale_pos_weight': 2.7984184778875543,\n",
    "    'device': 'gpu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f93a200d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-12T07:34:29.462746Z",
     "iopub.status.busy": "2024-10-12T07:34:29.462426Z",
     "iopub.status.idle": "2024-10-12T07:34:29.466823Z",
     "shell.execute_reply": "2024-10-12T07:34:29.466046Z"
    },
    "papermill": {
     "duration": 0.021751,
     "end_time": "2024-10-12T07:34:29.468628",
     "exception": false,
     "start_time": "2024-10-12T07:34:29.446877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cb_params = {\n",
    "#     'loss_function':     'Logloss',\n",
    "#     'iterations':        250,\n",
    "#     'verbose':           False,\n",
    "#     'random_state':      seed,\n",
    "#     'max_depth':         7,\n",
    "#     'learning_rate':     0.06936242010150652,\n",
    "#     'scale_pos_weight':  2.6149345838209532,\n",
    "#     'l2_leaf_reg':       6.216113851699493,\n",
    "#     'subsample':         0.6249261779711819,\n",
    "#     'min_data_in_leaf':  24,\n",
    "#     'cat_features':      cat_cols,\n",
    "    \n",
    "# }\n",
    "# cb_model2 = Pipeline([\n",
    "#     ('sampler_1', RandomOverSampler(sampling_strategy= 0.003 , random_state=seed)),\n",
    "#     ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=seed)),\n",
    "#     ('classifier', cb.CatBoostClassifier(**cb_params)),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42d70004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-12T07:34:29.494326Z",
     "iopub.status.busy": "2024-10-12T07:34:29.494055Z",
     "iopub.status.idle": "2024-10-12T07:34:29.498437Z",
     "shell.execute_reply": "2024-10-12T07:34:29.497614Z"
    },
    "papermill": {
     "duration": 0.01941,
     "end_time": "2024-10-12T07:34:29.500329",
     "exception": false,
     "start_time": "2024-10-12T07:34:29.480919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xgb_params = {\n",
    "#     'enable_categorical': True,\n",
    "#     'tree_method':        'hist',\n",
    "#     'random_state':       seed,\n",
    "#     'learning_rate':      0.08501257473292347,\n",
    "#     'lambda':             8.879624125465703,\n",
    "#     'alpha':              0.6779926606782505,\n",
    "#     'max_depth':          6,\n",
    "#     'subsample':          0.6012681388711075,\n",
    "#     'colsample_bytree':   0.8437772277074493,\n",
    "#     'colsample_bylevel':  0.5476090898823716,\n",
    "#     'colsample_bynode':   0.9928601203635129,\n",
    "#     'scale_pos_weight':   3.29440313334688,\n",
    "# }\n",
    "\n",
    "# xgb_model2 = Pipeline([\n",
    "#     ('sampler_1', RandomOverSampler(sampling_strategy= 0.003 , random_state=seed)),\n",
    "#     ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=seed)),\n",
    "#     ('classifier', xgb.XGBClassifier(**xgb_params)),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aac747",
   "metadata": {
    "papermill": {
     "duration": 0.012148,
     "end_time": "2024-10-12T07:34:29.525034",
     "exception": false,
     "start_time": "2024-10-12T07:34:29.512886",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">TRAINING</h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "513351d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-12T07:34:29.552154Z",
     "iopub.status.busy": "2024-10-12T07:34:29.551342Z",
     "iopub.status.idle": "2024-10-12T07:35:20.722197Z",
     "shell.execute_reply": "2024-10-12T07:35:20.721265Z"
    },
    "papermill": {
     "duration": 51.186574,
     "end_time": "2024-10-12T07:35:20.724178",
     "exception": false,
     "start_time": "2024-10-12T07:34:29.537604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lgb1&#x27;,\n",
       "                              Pipeline(steps=[(&#x27;sampler_1&#x27;,\n",
       "                                               RandomOverSampler(random_state=12,\n",
       "                                                                 sampling_strategy=0.003)),\n",
       "                                              (&#x27;sampler_2&#x27;,\n",
       "                                               RandomUnderSampler(random_state=12,\n",
       "                                                                  sampling_strategy=0.01)),\n",
       "                                              (&#x27;filter&#x27;,\n",
       "                                               SelectColumns(columns=[&#x27;age_approx&#x27;,\n",
       "                                                                      &#x27;clin_size_long_diam_mm&#x27;,\n",
       "                                                                      &#x27;tbp_lv_A&#x27;,\n",
       "                                                                      &#x27;tbp_lv_Aext&#x27;,\n",
       "                                                                      &#x27;tbp_lv_B&#x27;,\n",
       "                                                                      &#x27;tbp_lv_Bext&#x27;,\n",
       "                                                                      &#x27;tbp_lv_C&#x27;,\n",
       "                                                                      &#x27;tbp_lv_Cext&#x27;,\n",
       "                                                                      &#x27;tbp_...\n",
       "                                               LGBMClassifier(bagging_fraction=0.7738954452473223,\n",
       "                                                              bagging_freq=4,\n",
       "                                                              colsample_bynode=0.4025961355653304,\n",
       "                                                              colsample_bytree=0.8329551585827726,\n",
       "                                                              device=&#x27;gpu&#x27;,\n",
       "                                                              lambda_l1=0.08758718919397321,\n",
       "                                                              lambda_l2=0.0039689175176025465,\n",
       "                                                              learning_rate=0.03231007103195577,\n",
       "                                                              max_depth=4,\n",
       "                                                              min_data_in_leaf=85,\n",
       "                                                              n_iter=200,\n",
       "                                                              num_leaves=103,\n",
       "                                                              objective=&#x27;binary&#x27;,\n",
       "                                                              scale_pos_weight=2.7984184778875543,\n",
       "                                                              verbosity=-1))]))],\n",
       "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lgb1&#x27;,\n",
       "                              Pipeline(steps=[(&#x27;sampler_1&#x27;,\n",
       "                                               RandomOverSampler(random_state=12,\n",
       "                                                                 sampling_strategy=0.003)),\n",
       "                                              (&#x27;sampler_2&#x27;,\n",
       "                                               RandomUnderSampler(random_state=12,\n",
       "                                                                  sampling_strategy=0.01)),\n",
       "                                              (&#x27;filter&#x27;,\n",
       "                                               SelectColumns(columns=[&#x27;age_approx&#x27;,\n",
       "                                                                      &#x27;clin_size_long_diam_mm&#x27;,\n",
       "                                                                      &#x27;tbp_lv_A&#x27;,\n",
       "                                                                      &#x27;tbp_lv_Aext&#x27;,\n",
       "                                                                      &#x27;tbp_lv_B&#x27;,\n",
       "                                                                      &#x27;tbp_lv_Bext&#x27;,\n",
       "                                                                      &#x27;tbp_lv_C&#x27;,\n",
       "                                                                      &#x27;tbp_lv_Cext&#x27;,\n",
       "                                                                      &#x27;tbp_...\n",
       "                                               LGBMClassifier(bagging_fraction=0.7738954452473223,\n",
       "                                                              bagging_freq=4,\n",
       "                                                              colsample_bynode=0.4025961355653304,\n",
       "                                                              colsample_bytree=0.8329551585827726,\n",
       "                                                              device=&#x27;gpu&#x27;,\n",
       "                                                              lambda_l1=0.08758718919397321,\n",
       "                                                              lambda_l2=0.0039689175176025465,\n",
       "                                                              learning_rate=0.03231007103195577,\n",
       "                                                              max_depth=4,\n",
       "                                                              min_data_in_leaf=85,\n",
       "                                                              n_iter=200,\n",
       "                                                              num_leaves=103,\n",
       "                                                              objective=&#x27;binary&#x27;,\n",
       "                                                              scale_pos_weight=2.7984184778875543,\n",
       "                                                              verbosity=-1))]))],\n",
       "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=12, sampling_strategy=0.003)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=12, sampling_strategy=0.01)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectColumns</label><div class=\"sk-toggleable__content\"><pre>SelectColumns(columns=[&#x27;age_approx&#x27;, &#x27;clin_size_long_diam_mm&#x27;, &#x27;tbp_lv_A&#x27;,\n",
       "                       &#x27;tbp_lv_Aext&#x27;, &#x27;tbp_lv_B&#x27;, &#x27;tbp_lv_Bext&#x27;, &#x27;tbp_lv_C&#x27;,\n",
       "                       &#x27;tbp_lv_Cext&#x27;, &#x27;tbp_lv_H&#x27;, &#x27;tbp_lv_Hext&#x27;, &#x27;tbp_lv_L&#x27;,\n",
       "                       &#x27;tbp_lv_Lext&#x27;, &#x27;tbp_lv_areaMM2&#x27;,\n",
       "                       &#x27;tbp_lv_area_perim_ratio&#x27;, &#x27;tbp_lv_color_std_mean&#x27;,\n",
       "                       &#x27;tbp_lv_deltaA&#x27;, &#x27;tbp_lv_deltaB&#x27;, &#x27;tbp_lv_deltaL&#x27;,\n",
       "                       &#x27;tbp_lv_deltaLB&#x27;, &#x27;tbp_lv_deltaLBnorm&#x27;,\n",
       "                       &#x27;tbp_lv_eccentricity&#x27;, &#x27;tbp_lv_minorAxisMM&#x27;,\n",
       "                       &#x27;tbp_lv_nevi_confidence&#x27;, &#x27;tbp_lv_norm_border&#x27;,\n",
       "                       &#x27;tbp_lv_norm_color&#x27;, &#x27;tbp_lv_perimeterMM&#x27;,\n",
       "                       &#x27;tbp_lv_radial_color_std_max&#x27;, &#x27;tbp_lv_stdL&#x27;,\n",
       "                       &#x27;tbp_lv_stdLExt&#x27;, &#x27;tbp_lv_symm_2axis&#x27;, ...])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.7738954452473223, bagging_freq=4,\n",
       "               colsample_bynode=0.4025961355653304,\n",
       "               colsample_bytree=0.8329551585827726, device=&#x27;gpu&#x27;,\n",
       "               lambda_l1=0.08758718919397321, lambda_l2=0.0039689175176025465,\n",
       "               learning_rate=0.03231007103195577, max_depth=4,\n",
       "               min_data_in_leaf=85, n_iter=200, num_leaves=103,\n",
       "               objective=&#x27;binary&#x27;, scale_pos_weight=2.7984184778875543,\n",
       "               verbosity=-1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=22, sampling_strategy=0.003)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=22, sampling_strategy=0.01)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.7738954452473223, bagging_freq=4,\n",
       "               colsample_bynode=0.4025961355653304,\n",
       "               colsample_bytree=0.8329551585827726, device=&#x27;gpu&#x27;,\n",
       "               lambda_l1=0.08758718919397321, lambda_l2=0.0039689175176025465,\n",
       "               learning_rate=0.03231007103195577, max_depth=4,\n",
       "               min_data_in_leaf=85, n_iter=200, num_leaves=103,\n",
       "               objective=&#x27;binary&#x27;, scale_pos_weight=2.7984184778875543,\n",
       "               verbosity=-1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb3</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=32, sampling_strategy=0.003)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=32, sampling_strategy=0.01)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectColumns</label><div class=\"sk-toggleable__content\"><pre>SelectColumns(columns=[&#x27;age_approx&#x27;, &#x27;clin_size_long_diam_mm&#x27;, &#x27;tbp_lv_A&#x27;,\n",
       "                       &#x27;tbp_lv_Aext&#x27;, &#x27;tbp_lv_B&#x27;, &#x27;tbp_lv_Bext&#x27;, &#x27;tbp_lv_C&#x27;,\n",
       "                       &#x27;tbp_lv_Cext&#x27;, &#x27;tbp_lv_H&#x27;, &#x27;tbp_lv_Hext&#x27;, &#x27;tbp_lv_L&#x27;,\n",
       "                       &#x27;tbp_lv_Lext&#x27;, &#x27;tbp_lv_areaMM2&#x27;,\n",
       "                       &#x27;tbp_lv_area_perim_ratio&#x27;, &#x27;tbp_lv_color_std_mean&#x27;,\n",
       "                       &#x27;tbp_lv_deltaA&#x27;, &#x27;tbp_lv_deltaB&#x27;, &#x27;tbp_lv_deltaL&#x27;,\n",
       "                       &#x27;tbp_lv_deltaLB&#x27;, &#x27;tbp_lv_deltaLBnorm&#x27;,\n",
       "                       &#x27;tbp_lv_eccentricity&#x27;, &#x27;tbp_lv_minorAxisMM&#x27;,\n",
       "                       &#x27;tbp_lv_nevi_confidence&#x27;, &#x27;tbp_lv_norm_border&#x27;,\n",
       "                       &#x27;tbp_lv_norm_color&#x27;, &#x27;tbp_lv_perimeterMM&#x27;,\n",
       "                       &#x27;tbp_lv_radial_color_std_max&#x27;, &#x27;tbp_lv_stdL&#x27;,\n",
       "                       &#x27;tbp_lv_stdLExt&#x27;, &#x27;tbp_lv_symm_2axis&#x27;, ...])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.7738954452473223, bagging_freq=4,\n",
       "               colsample_bynode=0.4025961355653304,\n",
       "               colsample_bytree=0.8329551585827726, device=&#x27;gpu&#x27;,\n",
       "               lambda_l1=0.08758718919397321, lambda_l2=0.0039689175176025465,\n",
       "               learning_rate=0.03231007103195577, max_depth=4,\n",
       "               min_data_in_leaf=85, n_iter=200, num_leaves=103,\n",
       "               objective=&#x27;binary&#x27;, scale_pos_weight=2.7984184778875543,\n",
       "               verbosity=-1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb4</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=42, sampling_strategy=0.003)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=42, sampling_strategy=0.01)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.7738954452473223, bagging_freq=4,\n",
       "               colsample_bynode=0.4025961355653304,\n",
       "               colsample_bytree=0.8329551585827726, device=&#x27;gpu&#x27;,\n",
       "               lambda_l1=0.08758718919397321, lambda_l2=0.0039689175176025465,\n",
       "               learning_rate=0.03231007103195577, max_depth=4,\n",
       "               min_data_in_leaf=85, n_iter=200, num_leaves=103,\n",
       "               objective=&#x27;binary&#x27;, scale_pos_weight=2.7984184778875543,\n",
       "               verbosity=-1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb5</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=52, sampling_strategy=0.003)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=52, sampling_strategy=0.01)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectColumns</label><div class=\"sk-toggleable__content\"><pre>SelectColumns(columns=[&#x27;age_approx&#x27;, &#x27;clin_size_long_diam_mm&#x27;, &#x27;tbp_lv_A&#x27;,\n",
       "                       &#x27;tbp_lv_Aext&#x27;, &#x27;tbp_lv_B&#x27;, &#x27;tbp_lv_Bext&#x27;, &#x27;tbp_lv_C&#x27;,\n",
       "                       &#x27;tbp_lv_Cext&#x27;, &#x27;tbp_lv_H&#x27;, &#x27;tbp_lv_Hext&#x27;, &#x27;tbp_lv_L&#x27;,\n",
       "                       &#x27;tbp_lv_Lext&#x27;, &#x27;tbp_lv_areaMM2&#x27;,\n",
       "                       &#x27;tbp_lv_area_perim_ratio&#x27;, &#x27;tbp_lv_color_std_mean&#x27;,\n",
       "                       &#x27;tbp_lv_deltaA&#x27;, &#x27;tbp_lv_deltaB&#x27;, &#x27;tbp_lv_deltaL&#x27;,\n",
       "                       &#x27;tbp_lv_deltaLB&#x27;, &#x27;tbp_lv_deltaLBnorm&#x27;,\n",
       "                       &#x27;tbp_lv_eccentricity&#x27;, &#x27;tbp_lv_minorAxisMM&#x27;,\n",
       "                       &#x27;tbp_lv_nevi_confidence&#x27;, &#x27;tbp_lv_norm_border&#x27;,\n",
       "                       &#x27;tbp_lv_norm_color&#x27;, &#x27;tbp_lv_perimeterMM&#x27;,\n",
       "                       &#x27;tbp_lv_radial_color_std_max&#x27;, &#x27;tbp_lv_stdL&#x27;,\n",
       "                       &#x27;tbp_lv_stdLExt&#x27;, &#x27;tbp_lv_symm_2axis&#x27;, ...])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.7738954452473223, bagging_freq=4,\n",
       "               colsample_bynode=0.4025961355653304,\n",
       "               colsample_bytree=0.8329551585827726, device=&#x27;gpu&#x27;,\n",
       "               lambda_l1=0.08758718919397321, lambda_l2=0.0039689175176025465,\n",
       "               learning_rate=0.03231007103195577, max_depth=4,\n",
       "               min_data_in_leaf=85, n_iter=200, num_leaves=103,\n",
       "               objective=&#x27;binary&#x27;, scale_pos_weight=2.7984184778875543,\n",
       "               verbosity=-1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb6</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=62, sampling_strategy=0.003)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=62, sampling_strategy=0.01)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.7738954452473223, bagging_freq=4,\n",
       "               colsample_bynode=0.4025961355653304,\n",
       "               colsample_bytree=0.8329551585827726, device=&#x27;gpu&#x27;,\n",
       "               lambda_l1=0.08758718919397321, lambda_l2=0.0039689175176025465,\n",
       "               learning_rate=0.03231007103195577, max_depth=4,\n",
       "               min_data_in_leaf=85, n_iter=200, num_leaves=103,\n",
       "               objective=&#x27;binary&#x27;, scale_pos_weight=2.7984184778875543,\n",
       "               verbosity=-1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb7</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=111, sampling_strategy=0.003)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=111, sampling_strategy=0.01)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectColumns</label><div class=\"sk-toggleable__content\"><pre>SelectColumns(columns=[&#x27;age_approx&#x27;, &#x27;clin_size_long_diam_mm&#x27;, &#x27;tbp_lv_A&#x27;,\n",
       "                       &#x27;tbp_lv_Aext&#x27;, &#x27;tbp_lv_B&#x27;, &#x27;tbp_lv_Bext&#x27;, &#x27;tbp_lv_C&#x27;,\n",
       "                       &#x27;tbp_lv_Cext&#x27;, &#x27;tbp_lv_H&#x27;, &#x27;tbp_lv_Hext&#x27;, &#x27;tbp_lv_L&#x27;,\n",
       "                       &#x27;tbp_lv_Lext&#x27;, &#x27;tbp_lv_areaMM2&#x27;,\n",
       "                       &#x27;tbp_lv_area_perim_ratio&#x27;, &#x27;tbp_lv_color_std_mean&#x27;,\n",
       "                       &#x27;tbp_lv_deltaA&#x27;, &#x27;tbp_lv_deltaB&#x27;, &#x27;tbp_lv_deltaL&#x27;,\n",
       "                       &#x27;tbp_lv_deltaLB&#x27;, &#x27;tbp_lv_deltaLBnorm&#x27;,\n",
       "                       &#x27;tbp_lv_eccentricity&#x27;, &#x27;tbp_lv_minorAxisMM&#x27;,\n",
       "                       &#x27;tbp_lv_nevi_confidence&#x27;, &#x27;tbp_lv_norm_border&#x27;,\n",
       "                       &#x27;tbp_lv_norm_color&#x27;, &#x27;tbp_lv_perimeterMM&#x27;,\n",
       "                       &#x27;tbp_lv_radial_color_std_max&#x27;, &#x27;tbp_lv_stdL&#x27;,\n",
       "                       &#x27;tbp_lv_stdLExt&#x27;, &#x27;tbp_lv_symm_2axis&#x27;, ...])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.7738954452473223, bagging_freq=4,\n",
       "               colsample_bynode=0.4025961355653304,\n",
       "               colsample_bytree=0.8329551585827726, device=&#x27;gpu&#x27;,\n",
       "               lambda_l1=0.08758718919397321, lambda_l2=0.0039689175176025465,\n",
       "               learning_rate=0.03231007103195577, max_depth=4,\n",
       "               min_data_in_leaf=85, n_iter=200, num_leaves=103,\n",
       "               objective=&#x27;binary&#x27;, scale_pos_weight=2.7984184778875543,\n",
       "               verbosity=-1)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('lgb1',\n",
       "                              Pipeline(steps=[('sampler_1',\n",
       "                                               RandomOverSampler(random_state=12,\n",
       "                                                                 sampling_strategy=0.003)),\n",
       "                                              ('sampler_2',\n",
       "                                               RandomUnderSampler(random_state=12,\n",
       "                                                                  sampling_strategy=0.01)),\n",
       "                                              ('filter',\n",
       "                                               SelectColumns(columns=['age_approx',\n",
       "                                                                      'clin_size_long_diam_mm',\n",
       "                                                                      'tbp_lv_A',\n",
       "                                                                      'tbp_lv_Aext',\n",
       "                                                                      'tbp_lv_B',\n",
       "                                                                      'tbp_lv_Bext',\n",
       "                                                                      'tbp_lv_C',\n",
       "                                                                      'tbp_lv_Cext',\n",
       "                                                                      'tbp_...\n",
       "                                               LGBMClassifier(bagging_fraction=0.7738954452473223,\n",
       "                                                              bagging_freq=4,\n",
       "                                                              colsample_bynode=0.4025961355653304,\n",
       "                                                              colsample_bytree=0.8329551585827726,\n",
       "                                                              device='gpu',\n",
       "                                                              lambda_l1=0.08758718919397321,\n",
       "                                                              lambda_l2=0.0039689175176025465,\n",
       "                                                              learning_rate=0.03231007103195577,\n",
       "                                                              max_depth=4,\n",
       "                                                              min_data_in_leaf=85,\n",
       "                                                              n_iter=200,\n",
       "                                                              num_leaves=103,\n",
       "                                                              objective='binary',\n",
       "                                                              scale_pos_weight=2.7984184778875543,\n",
       "                                                              verbosity=-1))]))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df_train[feature_cols], df_train[target_col]\n",
    "\n",
    "estimator = VotingClassifier([\n",
    "    ('lgb1', Pipeline([\n",
    "        ('sampler_1', RandomOverSampler(sampling_strategy=0.003,random_state=12)),\n",
    "        ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=12)),\n",
    "        ('filter', SelectColumns(feature_cols_without_image_cols)),\n",
    "        ('classifier', lgb.LGBMClassifier(**lgb_params)),\n",
    "    ])),\n",
    "    ('lgb2', Pipeline([\n",
    "        ('sampler_1', RandomOverSampler(sampling_strategy= 0.003 , random_state=22)),\n",
    "        ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=22)),\n",
    "        ('classifier', lgb.LGBMClassifier(**lgb_params)),\n",
    "    ])),\n",
    "    ('lgb3', Pipeline([\n",
    "        ('sampler_1', RandomOverSampler(sampling_strategy=0.003,random_state=32)),\n",
    "        ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=32)),\n",
    "        ('filter', SelectColumns(feature_cols_without_image_cols)),\n",
    "        ('classifier', lgb.LGBMClassifier(**lgb_params)),\n",
    "    ])),\n",
    "    ('lgb4', Pipeline([\n",
    "        ('sampler_1', RandomOverSampler(sampling_strategy= 0.003 , random_state=42)),\n",
    "        ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=42)),\n",
    "        ('classifier', lgb.LGBMClassifier(**lgb_params)),\n",
    "    ])),\n",
    "    ('lgb5', Pipeline([\n",
    "        ('sampler_1', RandomOverSampler(sampling_strategy=0.003,random_state=52)),\n",
    "        ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=52)),\n",
    "        ('filter', SelectColumns(feature_cols_without_image_cols)),\n",
    "        ('classifier', lgb.LGBMClassifier(**lgb_params)),\n",
    "    ])),\n",
    "    ('lgb6', Pipeline([\n",
    "        ('sampler_1', RandomOverSampler(sampling_strategy= 0.003 , random_state=62)),\n",
    "        ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=62)),\n",
    "        ('classifier', lgb.LGBMClassifier(**lgb_params)),\n",
    "    ])),\n",
    "    ('lgb7', Pipeline([\n",
    "        ('sampler_1', RandomOverSampler(sampling_strategy=0.003,random_state=111)),\n",
    "        ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=111)),\n",
    "        ('filter', SelectColumns(feature_cols_without_image_cols)),\n",
    "        ('classifier', lgb.LGBMClassifier(**lgb_params)),\n",
    "    ])),\n",
    "], voting='soft')\n",
    "\n",
    "estimator.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89088bc",
   "metadata": {
    "papermill": {
     "duration": 0.014919,
     "end_time": "2024-10-12T07:35:20.754615",
     "exception": false,
     "start_time": "2024-10-12T07:35:20.739696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">PREDICTION</h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc97ba19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-12T07:35:20.786524Z",
     "iopub.status.busy": "2024-10-12T07:35:20.785691Z",
     "iopub.status.idle": "2024-10-12T07:35:21.004662Z",
     "shell.execute_reply": "2024-10-12T07:35:21.003633Z"
    },
    "papermill": {
     "duration": 0.237244,
     "end_time": "2024-10-12T07:35:21.006951",
     "exception": false,
     "start_time": "2024-10-12T07:35:20.769707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isic_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ISIC_0015657</th>\n",
       "      <td>0.585758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0015729</th>\n",
       "      <td>0.519024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0015740</th>\n",
       "      <td>0.614877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                target\n",
       "isic_id               \n",
       "ISIC_0015657  0.585758\n",
       "ISIC_0015729  0.519024\n",
       "ISIC_0015740  0.614877"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subm['target'] = estimator.predict_proba(df_test[feature_cols])[:, 1]\n",
    "\n",
    "df_subm.to_csv('submission.csv')\n",
    "df_subm.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9094797,
     "sourceId": 63056,
     "sourceType": "competition"
    },
    {
     "datasetId": 5415918,
     "sourceId": 8991790,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5858402,
     "sourceId": 9602492,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 188603902,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 124.750207,
   "end_time": "2024-10-12T07:35:23.824519",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-12T07:33:19.074312",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
